{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer Proyecto Individual en la Etapa de Labs en HENRY.\n",
    "\n",
    "#### Sección para la limpieza de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Consideraciones a tratar en este paso:\n",
    "\n",
    "* Algunos campos, como belongs_to_collection, production_companies y otros (ver diccionario de datos) están anidados, esto es o bien tienen un diccionario o una lista como valores en cada fila, ¡deberán desanidarlos y unirlos al dataset de nuevo para hacer alguna de las consultas de la API! O bien buscar la manera de acceder a esos datos sin desanidarlos..\n",
    "\n",
    "* Los valores nulos de los campos revenue, budget deben ser rellenados por el número 0.\n",
    "\n",
    "* Los valores nulos del campo release date deben eliminarse.\n",
    "\n",
    "* De haber fechas, deberán tener el formato AAAA-mm-dd, además deberán crear la columna release_year donde extraerán el año de la fecha de estreno.\n",
    "\n",
    "* Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget, cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0.\n",
    "\n",
    "* Eliminar las columnas que no serán utilizadas, video,imdb_id,adult,original_title,poster_path y homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del dataset \"movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24196\\3219681389.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv('Data/movies_dataset.csv')\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24196\\3219681389.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['row_count'] = df.sort_values(by=['title','release_date'],ascending=False).groupby(['title']).cumcount()+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas eliminadas del dataset por no contener información relevante:            id_peli title                            budget original_language  \\\n",
      "17925  1997-08-20   NaN  /ff9qCepilowshEtG2GYWwzt2bs4.jpg             104.0   \n",
      "27013  2012-09-29   NaN  /zV8bHuSL6WXoD6FWogP9j4x80bL.jpg              68.0   \n",
      "32768  2014-01-01   NaN  /zaSf5OG7V8X8gqFvly88zDdRm46.jpg              82.0   \n",
      "\n",
      "      release_date  revenue  runtime production_companies  \\\n",
      "17925            1      NaN      NaN                False   \n",
      "27013           12      NaN      NaN                False   \n",
      "32768           22      NaN      NaN                False   \n",
      "\n",
      "      belongs_to_collection production_countries  \\\n",
      "17925              0.065736                  6.0   \n",
      "27013              1.931659                  7.0   \n",
      "32768              2.185485                  4.3   \n",
      "\n",
      "                                                  genres  overview  \\\n",
      "17925  [{'name': 'Carousel Productions', 'id': 11176}...  Released   \n",
      "27013  [{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...  Released   \n",
      "32768  [{'name': 'Odyssey Media', 'id': 17161}, {'nam...  Released   \n",
      "\n",
      "                  popularity spoken_languages status tagline  vote_average  \\\n",
      "17925                    NaN              NaN    NaN     NaN           NaN   \n",
      "27013                    NaN              NaN    NaN     NaN           NaN   \n",
      "32768  Beware Of Frost Bites              NaN    NaN     NaN           NaN   \n",
      "\n",
      "       vote_count  \n",
      "17925         NaN  \n",
      "27013         NaN  \n",
      "32768         NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24196\\3219681389.py:76: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  movies_df['return'] = pd.Series()\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24196\\3219681389.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_df['return'][i] = x[i]/y[i] if y[i] != 0 else 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>return</th>\n",
       "      <th>original_language</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>12.451801</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>81.0</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>4.043035</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting To Exhale</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>5.090760</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father Of The Bride Part Ii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41760</th>\n",
       "      <td>222848</td>\n",
       "      <td>Caged Heat 3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.661558</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>111109</td>\n",
       "      <td>Century Of Birthing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tl</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41762</th>\n",
       "      <td>67758</td>\n",
       "      <td>Betrayal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-08-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.903007</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>227506</td>\n",
       "      <td>Satan Triumphant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1917</td>\n",
       "      <td>1917-10-21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41764</th>\n",
       "      <td>461257</td>\n",
       "      <td>Queerama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.163015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41765 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                        title      budget      revenue  \\\n",
       "0          862                    Toy Story  30000000.0  373554033.0   \n",
       "1         8844                      Jumanji  65000000.0  262797249.0   \n",
       "2        15602             Grumpier Old Men         0.0          0.0   \n",
       "3        31357            Waiting To Exhale  16000000.0   81452156.0   \n",
       "4        11862  Father Of The Bride Part Ii         0.0   76578911.0   \n",
       "...        ...                          ...         ...          ...   \n",
       "41760   222848              Caged Heat 3000         0.0          0.0   \n",
       "41761   111109          Century Of Birthing         0.0          0.0   \n",
       "41762    67758                     Betrayal         0.0          0.0   \n",
       "41763   227506             Satan Triumphant         0.0          0.0   \n",
       "41764   461257                     Queerama         0.0          0.0   \n",
       "\n",
       "          return original_language  release_year release_date  runtime  \\\n",
       "0      12.451801                en          1995   1995-10-30     81.0   \n",
       "1       4.043035                en          1995   1995-12-15    104.0   \n",
       "2       0.000000                en          1995   1995-12-22    101.0   \n",
       "3       5.090760                en          1995   1995-12-22    127.0   \n",
       "4       0.000000                en          1995   1995-02-10    106.0   \n",
       "...          ...               ...           ...          ...      ...   \n",
       "41760   0.000000                en          1995   1995-01-01     85.0   \n",
       "41761   0.000000                tl          2011   2011-11-17    360.0   \n",
       "41762   0.000000                en          2003   2003-08-01     90.0   \n",
       "41763   0.000000                en          1917   1917-10-21     87.0   \n",
       "41764   0.000000                en          2017   2017-06-09     75.0   \n",
       "\n",
       "       popularity  vote_average  vote_count  \n",
       "0       21.946943           7.7      5415.0  \n",
       "1       17.015539           6.9      2413.0  \n",
       "2       11.712900           6.5        92.0  \n",
       "3        3.859495           6.1        34.0  \n",
       "4        8.387519           5.7       173.0  \n",
       "...           ...           ...         ...  \n",
       "41760    0.661558           3.5         1.0  \n",
       "41761    0.178241           9.0         3.0  \n",
       "41762    0.903007           3.8         6.0  \n",
       "41763    0.003503           0.0         0.0  \n",
       "41764    0.163015           0.0         0.0  \n",
       "\n",
       "[41765 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos el dataset hacia un dataframe en python.\n",
    "movies_df = pd.read_csv('Data/movies_dataset.csv')\n",
    "\n",
    "# Seleccionamos las columnas que necesitamos y eliminamos las que nos piden: video,imdb_id,adult,original_title,poster_path,homepage. Y renombramos algunas.\n",
    "movies_df = movies_df[['id', 'title', 'budget', 'original_language', 'release_date', 'revenue', 'runtime', 'production_companies',  \n",
    "        'belongs_to_collection', 'production_countries', 'genres', 'overview', 'popularity',\n",
    "        'spoken_languages', 'status', 'tagline', 'vote_average', 'vote_count']]\n",
    "movies_df.columns = ['id_peli', 'title', 'budget', 'original_language', 'release_date', 'revenue', 'runtime', 'production_companies',  \n",
    "        'belongs_to_collection', 'production_countries', 'genres', 'overview', 'popularity',\n",
    "        'spoken_languages', 'status', 'tagline', 'vote_average', 'vote_count']\n",
    "\n",
    "# Eliminamos los campos nulos de la columna \"release_date\".\n",
    "movies_df = movies_df.dropna(subset=['release_date']).reset_index(drop=True)\n",
    "\n",
    "# Eliminamos películas duplicadas. Para este caso, tomamos las películas duplicadas con fecha de lanzamiento más reciente.\n",
    "df = movies_df[movies_df.title.isin(list(movies_df[movies_df.title.duplicated()].title))]\n",
    "df['row_count'] = df.sort_values(by=['title','release_date'],ascending=False).groupby(['title']).cumcount()+1\n",
    "index = list(df[df.row_count > 1].id_peli)\n",
    "movies_df = movies_df.set_index('id_peli')\n",
    "movies_df = movies_df.drop(index).reset_index()\n",
    "\n",
    "# Transformando los datos del \"id\" de película a enteros: Me di cuenta mediante este proceso de que existen 3 \"id's\" que son fechas, por lo que eliminé dichas filas.\n",
    "index = []\n",
    "for i in range(len(movies_df)):\n",
    "    try:\n",
    "        movies_df.loc[i,['id_peli']] = int(movies_df.id_peli[i])\n",
    "    except ValueError:\n",
    "        index.append(i)\n",
    "\n",
    "# Visualizamos las filas que no contienen datos relevantes: index = [19714,29472,35543]      \n",
    "print('Filas eliminadas del dataset por no contener información relevante: ',movies_df.loc[index])\n",
    "\n",
    "# Eliminamos las filas.\n",
    "movies_df = movies_df.drop(index)\n",
    "\n",
    "# Seleccionamos las películas con \"status\" = 'Released'.\n",
    "movies_df = movies_df[movies_df.status == 'Released']\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Por último vamos a examinar si existen filas duplicadas en nuestro dataframe.\n",
    "# Utilizamos primeramente el método drop_duplicates().\n",
    "movies_df = movies_df.drop_duplicates()\n",
    "\n",
    "# Después buscamos si existen \"id's\" repetidos después del método.\n",
    "dfx = movies_df.groupby('id_peli')['id_peli'].count() > 1\n",
    "dfx = pd.DataFrame(dfx)\n",
    "index = list(dfx[dfx.id_peli == True].index)\n",
    "\n",
    "# Creamos un DF temporal con el objetivo de obtener las filas con 'id's' duplicados.\n",
    "dfx = pd.DataFrame()\n",
    "for i in index:\n",
    "    dfx = pd.concat([dfx,movies_df[movies_df.id_peli == i]])\n",
    "\n",
    "# Tomamos las filas duplicadas que están en segundo lugar y las eliminamos.\n",
    "index = list(dfx[1::2].index)\n",
    "movies_df = movies_df.drop(index).reset_index(drop=True)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Rellenar valores nulos en los campos \"budget\" y \"revenue\" por 0.\n",
    "movies_df['revenue'] = movies_df.revenue.fillna(0)\n",
    "movies_df['budget'] = movies_df.budget.fillna(0)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# De haber fechas, deberán tener el formato AAAA-mm-dd, además, deberán crear la columna \"release_year\", donde extraerán el año de la fecha de estreno.\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df['release_date'])\n",
    "movies_df['release_year'] = movies_df['release_date'].apply(lambda x: x.year)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget, cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0.\n",
    "movies_df['budget'] = movies_df.budget.astype(float)\n",
    "def returns(x,y):\n",
    "    movies_df['return'] = pd.Series()\n",
    "    for i in range(len(x)):\n",
    "        movies_df['return'][i] = x[i]/y[i] if y[i] != 0 else 0\n",
    "returns(movies_df.revenue,movies_df.budget)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Creamos una función lambda que nos va a ayudar a pasar los strings a listas de diccionarios.\n",
    "a_lista = lambda x: eval(x)\n",
    "\n",
    "# Separamos las columnas con sus respectivos \"id_peli\" en 5 diferentes DF's.\n",
    "df1 = movies_df[['id_peli','production_companies']].reset_index(drop=True)\n",
    "df2 = movies_df[['id_peli','belongs_to_collection']].reset_index(drop=True)\n",
    "df3 = movies_df[['id_peli','production_countries']].reset_index(drop=True)\n",
    "df4 = movies_df[['id_peli','genres']].reset_index(drop=True)\n",
    "df5 = movies_df[['id_peli','spoken_languages']].reset_index(drop=True)\n",
    "\n",
    "# Ahora que ya hemos utilizado las columnas que necesitamos para desanidar las columnas anidadas, podemos eliminarlas de nuestro dataframe de películas, ya que la información está en\n",
    "# nuevos dataframes.\n",
    "movies_df = movies_df[['id_peli', 'title', 'budget', 'revenue', 'return', 'original_language', 'release_year', 'release_date', 'runtime', 'popularity', 'vote_average', 'vote_count']]\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Convertimos los campos anidados de nuestro dataset inicial, de strings a listas de diccionarios. En total son 5 columnas anidadas.\n",
    "df1['production_companies'] = df1['production_companies'].apply(a_lista)\n",
    "\n",
    "df2 = df2.dropna().reset_index(drop=True)\n",
    "df2['belongs_to_collection'] = df2['belongs_to_collection'].apply(a_lista)\n",
    "\n",
    "df3['production_countries'] = df3['production_countries'].apply(a_lista)\n",
    "\n",
    "df4['genres'] = df4['genres'].apply(a_lista)\n",
    "\n",
    "df5 = df5.dropna().reset_index(drop=True)\n",
    "df5['spoken_languages'] = df5['spoken_languages'].apply(a_lista)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Dejamos la columna \"release_date\" como datetime. Y capitalizamos las letras de los titulos para homogenizar.\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df.release_date)\n",
    "movies_df['title'] = movies_df.title.apply(lambda x: x.title())\n",
    "movies_df['original_language'] = movies_df.original_language.astype(str)\n",
    "movies_df['original_language'] = movies_df.original_language.apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "if not os.path.exists('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/'):\n",
    "    os.mkdir('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/')\n",
    "movies_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/movies.csv',index=False)\n",
    "\n",
    "# Visualizamos el dataframe.\n",
    "pd.read_csv('clean_data/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desanidado de columnas y creación de 5 nuevos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================================================================\n",
    "# Creación del DF \"productoras_df\" y del DF \"id_productoras_df\".\n",
    "# Lo que sigue es obtener el dataframe de las productoras asociadas a cada película.\n",
    "# sourcery skip: use-fstring-for-concatenation\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df1)):\n",
    "    df = pd.DataFrame(df1.production_companies[i])\n",
    "    df['id'] = df1.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "dfx.columns = ['productora','id_peli']\n",
    "\n",
    "# Ahora creamos el dataframe de las productoras únicas con un id único.\n",
    "productoras_df = dfx.productora.unique()\n",
    "productoras_df = pd.DataFrame(productoras_df,columns=['productora'])\n",
    "productoras_df = productoras_df.reset_index()\n",
    "productoras_df.columns = ['id_prod','productora']\n",
    "productoras_df['id_prod'] = productoras_df.id_prod.apply(lambda x: x+1)\n",
    "productoras_df['productora'] = productoras_df.productora.apply(lambda x: x.title())\n",
    "\n",
    "\n",
    "# Por último agregamos los \"id's\" de las productoras al dataframe de las productoras asociadas a películas y eliminamos la columna que contiene el nombre de la productora para reducir el \n",
    "# uso de memoria.\n",
    "dfx = dfx.merge(productoras_df)\n",
    "dfx = dfx.drop('productora',axis=1)\n",
    "id_productoras_df = dfx\n",
    "id_productoras_df['id_peli'] = id_productoras_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "productoras_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/productoras.csv',index=False)\n",
    "id_productoras_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/prod_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"franquicias_df\" y del DF \"id_franquicias_df\"\n",
    "# Obtenemos el dataframe de las franquicias asociadas a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df2)):\n",
    "    df = pd.DataFrame([df2.belongs_to_collection[i]])\n",
    "    df['id'] = df2.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de las franquicias únicas con un id único.\n",
    "dfx = dfx.drop(['poster_path','backdrop_path'],axis=1)\n",
    "dfx.columns = ['id_peli','franquicia']\n",
    "franquicias_df = dfx.franquicia.unique()\n",
    "franquicias_df = pd.DataFrame(franquicias_df,columns=['franquicia']).reset_index()\n",
    "franquicias_df.columns = ['id_franq','franquicia']\n",
    "franquicias_df['id_franq'] = franquicias_df.id_franq.apply(lambda x: x+1)\n",
    "franquicias_df = franquicias_df[['id_franq','franquicia']]\n",
    "franquicias_df['franquicia'] = franquicias_df.franquicia.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de las franquicias al dataframe de las franquicias asociadas a películas y eliminamos la columna que contiene el nombre de la franquicia para reducir el \n",
    "# uso de memoria.\n",
    "id_franquicias_df = dfx.merge(franquicias_df)\n",
    "id_franquicias_df = id_franquicias_df.drop(['franquicia'],axis=1)\n",
    "id_franquicias_df['id_peli'] = id_franquicias_df.id_peli.astype(int) \n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "franquicias_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/franquicias.csv',index=False)\n",
    "id_franquicias_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/franq_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"paises_df\" y del DF \"id_paises_df\"\n",
    "# Obtenemos el dataframe de los países asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df3)):\n",
    "    df = pd.DataFrame(df3.production_countries[i])\n",
    "    df['id'] = df3.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los países únicos con un id único.\n",
    "dfx.columns = ['iso_3166_1','pais','id_peli']\n",
    "dfx['dummy'] = dfx.iso_3166_1 + ' ' + dfx.pais\n",
    "paises_df = dfx.dummy.unique()\n",
    "paises_df = pd.DataFrame(paises_df,columns=['pais']).reset_index()\n",
    "paises_df.columns = ['id_pais','pais']\n",
    "paises_df['abrev'] = paises_df.pais.apply(lambda x: x[:2])\n",
    "paises_df['pais'] = paises_df.pais.apply(lambda x: x[3:])\n",
    "paises_df['id_pais'] = paises_df.id_pais.apply(lambda x: x + 1)\n",
    "paises_df['pais'] = paises_df.pais.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los países al dataframe de los países asociadas a películas y eliminamos la columna que contiene el nombre del país para reducir el \n",
    "# uso de memoria.\n",
    "id_paises_df = dfx.merge(paises_df)\n",
    "id_paises_df = id_paises_df.drop(['iso_3166_1','pais','dummy','abrev'],axis=1)\n",
    "id_paises_df['id_peli'] = id_paises_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "paises_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/paises.csv',index=False)\n",
    "id_paises_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/pais_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"generos_df\" y del DF \"id_generos_df\"\n",
    "# Obtenemos el dataframe de los generos asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df4)):\n",
    "    df = pd.DataFrame(df4.genres[i])\n",
    "    df['id'] = df4.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los generos únicos con un id único.\n",
    "dfx.columns = ['id_peli','genero']\n",
    "generos_df = pd.DataFrame(dfx.genero.unique(),columns=['genero']).reset_index()\n",
    "generos_df.columns = ['id_gen','genero']\n",
    "generos_df['id_gen'] = generos_df.id_gen.apply(lambda x: x + 1)\n",
    "generos_df['genero'] = generos_df.genero.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los generos al dataframe de los generos asociadas a películas y eliminamos la columna que contiene el nombre del genero para reducir el \n",
    "# uso de memoria.\n",
    "id_generos_df = dfx.merge(generos_df)\n",
    "id_generos_df = id_generos_df.drop(['genero'],axis=1)\n",
    "id_generos_df['id_peli'] = id_generos_df.id_peli.astype(int)\n",
    "id_generos_df.columns = ['id_peli','id_gen']\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "generos_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/generos.csv',index=False)\n",
    "id_generos_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/gen_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"lenguajes_df\" y del DF \"id_lenguajes_df\"\n",
    "# Obtenemos el dataframe de los lenguajes asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df5)):\n",
    "    df = pd.DataFrame(df5.spoken_languages[i])\n",
    "    df['id'] = df5.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los lenguajes únicos con un id único.\n",
    "dfx.columns = ['iso_639_1','lenguaje','id_peli']\n",
    "dfx['dummy'] = dfx.iso_639_1 + ' ' + dfx.lenguaje\n",
    "lenguajes_df = pd.DataFrame(dfx.dummy.unique(),columns=['lenguaje'])\n",
    "lenguajes_df['abrev'] = lenguajes_df.lenguaje.apply(lambda x: x[:2])\n",
    "lenguajes_df['lenguaje'] = lenguajes_df.lenguaje.apply(lambda x: x[3:])\n",
    "lenguajes_df = lenguajes_df.reset_index()\n",
    "lenguajes_df.columns = ['id_leng','lenguaje','abrev']\n",
    "lenguajes_df['id_leng'] = lenguajes_df.id_leng.apply(lambda x: x + 1)\n",
    "lenguajes_df = lenguajes_df[lenguajes_df.abrev.isin(list(movies_df.original_language.unique()))]\n",
    "lenguajes_df['lenguaje'] = lenguajes_df.lenguaje.apply(lambda x: x.title())\n",
    "lenguajes_df['abrev'] = lenguajes_df.abrev.apply(lambda x: x.lower())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los lenguajes al dataframe de los lenguajes asociadas a películas y eliminamos la columna que contiene el nombre del lenguaje para reducir el \n",
    "# uso de memoria.\n",
    "id_lenguajes_df = dfx.merge(lenguajes_df)\n",
    "id_lenguajes_df = id_lenguajes_df.drop(['iso_639_1','lenguaje','dummy','abrev'],axis=1)\n",
    "id_lenguajes_df['id_peli'] = id_lenguajes_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "lenguajes_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/lenguajes.csv',index=False)\n",
    "id_lenguajes_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/leng_movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del dataset \"credits.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================================================================\n",
    "# Ingresamos el dataset.\n",
    "credits_df = pd.read_csv('Data/credits.csv')\n",
    "\n",
    "# Dividimos el dataset en dos dataframe's\n",
    "elenco_df = credits_df[['id','cast']]\n",
    "productores_df = credits_df[['id','crew']]\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Eliminamos los nan, reestablecemos el índice y convertimos las strings en listas de diccionarios de ambos datasets.\n",
    "productores_df = productores_df.dropna().reset_index(drop=True)\n",
    "productores_df['crew'] = productores_df['crew'].apply(a_lista)\n",
    "elenco_df = elenco_df.dropna().reset_index(drop=True)\n",
    "elenco_df['cast'] = elenco_df['cast'].apply(a_lista)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Desanidamos la columna \"crew\".\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(productores_df)):\n",
    "    df = pd.DataFrame(productores_df.crew[i])\n",
    "    if not df.empty:\n",
    "        df = df[['id', 'job', 'name']][df.job == 'Director']\n",
    "        df = df.drop('job',axis=1)\n",
    "        df['id'] = productores_df.id[i]\n",
    "        dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Obtenemos solo los directores del dataset \"credits.csv\" y la tabla que asocia películas con directores.\n",
    "id_directores_df = dfx\n",
    "id_directores_df.columns = ['id_peli', 'director']\n",
    "directores_df = id_directores_df.director.unique()\n",
    "directores_df = pd.DataFrame(directores_df).reset_index()\n",
    "directores_df.columns = ['id_dir','director']\n",
    "directores_df['id_dir'] = directores_df.id_dir.apply(lambda x: x + 1)\n",
    "directores_df['director'] = directores_df.director.apply(lambda x: x.title())\n",
    "id_directores_df = id_directores_df.merge(directores_df).drop('director',axis=1)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Desanidamos la columna \"cast\" y creamos el dataframe de personajes.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(elenco_df)):\n",
    "    df = pd.DataFrame(elenco_df.cast[i])\n",
    "    if not df.empty:\n",
    "        df = df[['id', 'name']]\n",
    "        df['id'] = elenco_df.id[i]\n",
    "        dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "dfx.columns = ['id_peli', 'actor']\n",
    "id_personajes_actores_df = dfx\n",
    "\n",
    "# También creamos el dataset de actores con el mismo objetivo.\n",
    "dfx = id_personajes_actores_df.actor.unique()\n",
    "dfx = pd.DataFrame(dfx).reset_index()\n",
    "dfx.columns = ['id_act','actor']\n",
    "dfx['id_act'] = dfx.id_act.apply(lambda x: x + 1)\n",
    "dfx['actor'] = dfx.actor.apply(lambda x: x.title())\n",
    "actores_df = dfx\n",
    "\n",
    "# Ahora eliminamos la columna de actores y de personajes para solo dejar \"id's\"\n",
    "id_personajes_actores_df = id_personajes_actores_df.merge(actores_df)\n",
    "id_personajes_actores_df = id_personajes_actores_df.drop(['actor'],axis=1)\n",
    "id_personajes_actores_df\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creamos los archivos .csv de los dataframe's resultantes.\n",
    "directores_df.to_csv('clean_data/directores.csv',index=False)\n",
    "id_directores_df.to_csv('clean_data/dir_movies.csv',index=False)\n",
    "actores_df.to_csv('clean_data/actores.csv',index=False)\n",
    "id_personajes_actores_df.to_csv('clean_data/pers_movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección de desarrollo del dataset para el modelo de recomendación\n",
    "\n",
    "Esta parte de la limpieza se desarrolló a la par del desarrollo del EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24196\\196826973.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfx = pd.read_csv('Data/movies_dataset.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>title</th>\n",
       "      <th>original_language</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>en</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>en</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>en</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting To Exhale</td>\n",
       "      <td>en</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father Of The Bride Part Ii</td>\n",
       "      <td>en</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41760</th>\n",
       "      <td>222848</td>\n",
       "      <td>Caged Heat 3000</td>\n",
       "      <td>en</td>\n",
       "      <td>0.661558</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>111109</td>\n",
       "      <td>Century Of Birthing</td>\n",
       "      <td>tl</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41762</th>\n",
       "      <td>67758</td>\n",
       "      <td>Betrayal</td>\n",
       "      <td>en</td>\n",
       "      <td>0.903007</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>227506</td>\n",
       "      <td>Satan Triumphant</td>\n",
       "      <td>en</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41764</th>\n",
       "      <td>461257</td>\n",
       "      <td>Queerama</td>\n",
       "      <td>en</td>\n",
       "      <td>0.163015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41765 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                        title original_language  popularity  \\\n",
       "0          862                    Toy Story                en   21.946943   \n",
       "1         8844                      Jumanji                en   17.015539   \n",
       "2        15602             Grumpier Old Men                en   11.712900   \n",
       "3        31357            Waiting To Exhale                en    3.859495   \n",
       "4        11862  Father Of The Bride Part Ii                en    8.387519   \n",
       "...        ...                          ...               ...         ...   \n",
       "41760   222848              Caged Heat 3000                en    0.661558   \n",
       "41761   111109          Century Of Birthing                tl    0.178241   \n",
       "41762    67758                     Betrayal                en    0.903007   \n",
       "41763   227506             Satan Triumphant                en    0.003503   \n",
       "41764   461257                     Queerama                en    0.163015   \n",
       "\n",
       "       vote_average  vote_count  release_year  \n",
       "0               7.7      5415.0          1995  \n",
       "1               6.9      2413.0          1995  \n",
       "2               6.5        92.0          1995  \n",
       "3               6.1        34.0          1995  \n",
       "4               5.7       173.0          1995  \n",
       "...             ...         ...           ...  \n",
       "41760           3.5         1.0          1995  \n",
       "41761           9.0         3.0          2011  \n",
       "41762           3.8         6.0          2003  \n",
       "41763           0.0         0.0          1917  \n",
       "41764           0.0         0.0          2017  \n",
       "\n",
       "[41765 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# franquicia, genero, productora, paises, lenguaje, overview, release_year\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "dfx = pd.read_csv('Data/movies_dataset.csv')\n",
    "df = df[['id_peli', 'title', 'original_language', 'popularity', 'vote_average', 'vote_count', 'release_year']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45461</th>\n",
       "      <td>439050</td>\n",
       "      <td>Rising and falling between a man and woman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45462</th>\n",
       "      <td>111109</td>\n",
       "      <td>An artist struggles to finish his work while a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45463</th>\n",
       "      <td>67758</td>\n",
       "      <td>When one of her hits goes wrong, a professiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45464</th>\n",
       "      <td>227506</td>\n",
       "      <td>In a small town live two brothers, one a minis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45465</th>\n",
       "      <td>461257</td>\n",
       "      <td>50 years after decriminalisation of homosexual...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45463 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_peli                                           overview\n",
       "0         862  Led by Woody, Andy's toys live happily in his ...\n",
       "1        8844  When siblings Judy and Peter discover an encha...\n",
       "2       15602  A family wedding reignites the ancient feud be...\n",
       "3       31357  Cheated on, mistreated and stepped on, the wom...\n",
       "4       11862  Just when George Banks has recovered from his ...\n",
       "...       ...                                                ...\n",
       "45461  439050        Rising and falling between a man and woman.\n",
       "45462  111109  An artist struggles to finish his work while a...\n",
       "45463   67758  When one of her hits goes wrong, a professiona...\n",
       "45464  227506  In a small town live two brothers, one a minis...\n",
       "45465  461257  50 years after decriminalisation of homosexual...\n",
       "\n",
       "[45463 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = dfx[['id','overview']]\n",
    "index = []\n",
    "for i in range(len(dfx)):\n",
    "    try:\n",
    "        dfx.loc[i,['id']] = int(dfx.id[i])\n",
    "    except ValueError:\n",
    "        index.append(i)\n",
    "dfx.columns = ['id_peli','overview']\n",
    "dfx = dfx.drop(index)\n",
    "dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza que surgió durante el desarrollo del modelo.\n",
    "\n",
    "Parte del código que vamos a utilizar para generar esta parte de la limpieza la podemos obtener del EDA. Aunque también en esta parte comienza una parte del preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18788</th>\n",
       "      <td>The Castle Of Cloads</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19733</th>\n",
       "      <td>Narrien Illat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29612</th>\n",
       "      <td>Star Spangled Girl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20258</th>\n",
       "      <td>Hellyys</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36144</th>\n",
       "      <td>On Reflection: B.S. Johnson On Dr. Samuel Johnson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35182</th>\n",
       "      <td>Angel City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.068864</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26772</th>\n",
       "      <td>Cannabis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.069109</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31949</th>\n",
       "      <td>Day Of The Cobra</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.069176</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30953</th>\n",
       "      <td>Rolf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.069686</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23756</th>\n",
       "      <td>White Fang And The Hunter</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.069780</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5765 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  vote_count  \\\n",
       "18788                               The Castle Of Cloads         0.0   \n",
       "19733                                      Narrien Illat         0.0   \n",
       "29612                                 Star Spangled Girl         0.0   \n",
       "20258                                            Hellyys         0.0   \n",
       "36144  On Reflection: B.S. Johnson On Dr. Samuel Johnson         0.0   \n",
       "...                                                  ...         ...   \n",
       "35182                                         Angel City         2.0   \n",
       "26772                                           Cannabis         2.0   \n",
       "31949                                   Day Of The Cobra         2.0   \n",
       "30953                                               Rolf         2.0   \n",
       "23756                          White Fang And The Hunter         2.0   \n",
       "\n",
       "       popularity  release_year  \n",
       "18788    0.000000          1970  \n",
       "19733    0.000000          1970  \n",
       "29612    0.000000          1971  \n",
       "20258    0.000000          1972  \n",
       "36144    0.000000          1972  \n",
       "...           ...           ...  \n",
       "35182    0.068864          1977  \n",
       "26772    0.069109          1970  \n",
       "31949    0.069176          1980  \n",
       "30953    0.069686          1984  \n",
       "23756    0.069780          1975  \n",
       "\n",
       "[5765 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title','vote_count','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[:len(df) - 36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31904</th>\n",
       "      <td>Passage Of Venus</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.480371</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31901</th>\n",
       "      <td>Sallie Gardner At A Gallop</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.327841</td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38143</th>\n",
       "      <td>Buffalo Running</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.229221</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31897</th>\n",
       "      <td>Man Walking Around A Corner</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.184891</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31902</th>\n",
       "      <td>Traffic Crossing Leeds Bridge</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.490420</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31898</th>\n",
       "      <td>Accordion Player</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.212768</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37752</th>\n",
       "      <td>Mosquinha</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36598</th>\n",
       "      <td>Monkeyshines, No. 3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.276161</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31903</th>\n",
       "      <td>London'S Trafalgar Square</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.347100</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31899</th>\n",
       "      <td>Monkeyshines, No. 1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.163672</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31900</th>\n",
       "      <td>Monkeyshines, No. 2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.399258</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38296</th>\n",
       "      <td>Two Fencers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31909</th>\n",
       "      <td>Newark Athlete</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.806403</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25994</th>\n",
       "      <td>Dickson Greeting</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.041504</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32028</th>\n",
       "      <td>Men Boxing</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.619106</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32093</th>\n",
       "      <td>La Vague</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.173584</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37753</th>\n",
       "      <td>Je Vous Aime</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.212894</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29458</th>\n",
       "      <td>Poor Pierrot</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.673164</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32159</th>\n",
       "      <td>Fencing</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.205474</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32094</th>\n",
       "      <td>A Hand Shake</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.248422</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17257</th>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.061591</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38405</th>\n",
       "      <td>Hadj Cheriff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.076062</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38403</th>\n",
       "      <td>Sioux Ghost Dance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.154522</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38401</th>\n",
       "      <td>The Boxing Cats (Prof. Welton'S)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.227559</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17137</th>\n",
       "      <td>Dickson Experimental Sound Film</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.493914</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39187</th>\n",
       "      <td>Buffalo Dance</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.205698</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40214</th>\n",
       "      <td>Carmencita</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.273072</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41311</th>\n",
       "      <td>Luis Martinetti, Contortionist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.160054</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38332</th>\n",
       "      <td>Souvenir Strip Of The Edison Kinetoscope</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.809025</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39958</th>\n",
       "      <td>The Barbershop</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.247013</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>The Pickaninny Dance From The “Passing Show”</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.230014</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15821</th>\n",
       "      <td>Edison Kinetoscopic Record Of A Sneeze</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.312246</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38720</th>\n",
       "      <td>Falling Cat</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.467106</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39956</th>\n",
       "      <td>The Execution Of Mary, Queen Of Scots</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.938418</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36599</th>\n",
       "      <td>Wintergartenprogramm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.744847</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41721</th>\n",
       "      <td>Baignade En Mer</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.429666</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38402</th>\n",
       "      <td>Annabelle Serpentine Dance</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.584340</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21606</th>\n",
       "      <td>Tables Turned On The Gardener</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.963421</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23534</th>\n",
       "      <td>Workers Leaving The Lumière Factory</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38395</th>\n",
       "      <td>Baby'S Meal</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.402404</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40988</th>\n",
       "      <td>Playing Cards</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.325712</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18091</th>\n",
       "      <td>The Arrival Of A Train At La Ciotat</td>\n",
       "      <td>87.0</td>\n",
       "      <td>5.256608</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38409</th>\n",
       "      <td>Black Diamond Express</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036580</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41017</th>\n",
       "      <td>A Nightmare</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.444257</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30264</th>\n",
       "      <td>Arab Cortege, Geneva</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052557</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38407</th>\n",
       "      <td>A Morning Bath</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.262360</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41016</th>\n",
       "      <td>The Vanishing Lady</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.788113</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40993</th>\n",
       "      <td>A Terrible Night</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.017971</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38396</th>\n",
       "      <td>Panorama Du Grand Canal Pris D'Un Bateau</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.239236</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38397</th>\n",
       "      <td>Demolition Of A Wall</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.187422</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  vote_count  popularity  \\\n",
       "31904                              Passage Of Venus        19.0    0.480371   \n",
       "31901                    Sallie Gardner At A Gallop        25.0    0.327841   \n",
       "38143                               Buffalo Running         7.0    0.229221   \n",
       "31897                   Man Walking Around A Corner        17.0    1.184891   \n",
       "31902                 Traffic Crossing Leeds Bridge        25.0    1.490420   \n",
       "31898                              Accordion Player        18.0    0.212768   \n",
       "37752                                     Mosquinha         2.0    0.071756   \n",
       "36598                           Monkeyshines, No. 3         5.0    0.276161   \n",
       "31903                     London'S Trafalgar Square         9.0    0.347100   \n",
       "31899                           Monkeyshines, No. 1        15.0    1.163672   \n",
       "31900                           Monkeyshines, No. 2        12.0    0.399258   \n",
       "38296                                   Two Fencers         1.0    0.036471   \n",
       "31909                                Newark Athlete        15.0    0.806403   \n",
       "25994                              Dickson Greeting        13.0    1.041504   \n",
       "32028                                    Men Boxing         9.0    0.619106   \n",
       "32093                                      La Vague         5.0    0.173584   \n",
       "37753                                  Je Vous Aime         3.0    0.212894   \n",
       "29458                                  Poor Pierrot        19.0    0.673164   \n",
       "32159                                       Fencing         6.0    0.205474   \n",
       "32094                                  A Hand Shake         7.0    0.248422   \n",
       "17257                              Blacksmith Scene        19.0    1.061591   \n",
       "38405                                  Hadj Cheriff         2.0    0.076062   \n",
       "38403                             Sioux Ghost Dance         4.0    0.154522   \n",
       "38401              The Boxing Cats (Prof. Welton'S)         6.0    0.227559   \n",
       "17137               Dickson Experimental Sound Film        18.0    0.493914   \n",
       "39187                                 Buffalo Dance         6.0    0.205698   \n",
       "40214                                    Carmencita        18.0    1.273072   \n",
       "41311                Luis Martinetti, Contortionist         4.0    0.160054   \n",
       "38332      Souvenir Strip Of The Edison Kinetoscope         8.0    0.809025   \n",
       "39958                                The Barbershop         7.0    0.247013   \n",
       "39999  The Pickaninny Dance From The “Passing Show”         2.0    0.230014   \n",
       "15821        Edison Kinetoscopic Record Of A Sneeze        12.0    0.312246   \n",
       "38720                                   Falling Cat        13.0    1.467106   \n",
       "39956         The Execution Of Mary, Queen Of Scots        17.0    0.938418   \n",
       "36599                          Wintergartenprogramm         5.0    0.744847   \n",
       "41721                               Baignade En Mer        12.0    0.429666   \n",
       "38402                    Annabelle Serpentine Dance        20.0    1.584340   \n",
       "21606                 Tables Turned On The Gardener        44.0    1.963421   \n",
       "23534           Workers Leaving The Lumière Factory        52.0    0.693917   \n",
       "38395                                   Baby'S Meal        22.0    1.402404   \n",
       "40988                                 Playing Cards         9.0    0.325712   \n",
       "18091           The Arrival Of A Train At La Ciotat        87.0    5.256608   \n",
       "38409                         Black Diamond Express         1.0    0.036580   \n",
       "41017                                   A Nightmare        11.0    0.444257   \n",
       "30264                          Arab Cortege, Geneva         1.0    0.052557   \n",
       "38407                                A Morning Bath         5.0    0.262360   \n",
       "41016                            The Vanishing Lady        20.0    0.788113   \n",
       "40993                              A Terrible Night        13.0    1.017971   \n",
       "38396      Panorama Du Grand Canal Pris D'Un Bateau         7.0    0.239236   \n",
       "38397                          Demolition Of A Wall        17.0    1.187422   \n",
       "\n",
       "       release_year  \n",
       "31904          1874  \n",
       "31901          1878  \n",
       "38143          1883  \n",
       "31897          1887  \n",
       "31902          1888  \n",
       "31898          1888  \n",
       "37752          1890  \n",
       "36598          1890  \n",
       "31903          1890  \n",
       "31899          1890  \n",
       "31900          1890  \n",
       "38296          1891  \n",
       "31909          1891  \n",
       "25994          1891  \n",
       "32028          1891  \n",
       "32093          1891  \n",
       "37753          1891  \n",
       "29458          1892  \n",
       "32159          1892  \n",
       "32094          1892  \n",
       "17257          1893  \n",
       "38405          1894  \n",
       "38403          1894  \n",
       "38401          1894  \n",
       "17137          1894  \n",
       "39187          1894  \n",
       "40214          1894  \n",
       "41311          1894  \n",
       "38332          1894  \n",
       "39958          1894  \n",
       "39999          1894  \n",
       "15821          1894  \n",
       "38720          1894  \n",
       "39956          1895  \n",
       "36599          1895  \n",
       "41721          1895  \n",
       "38402          1895  \n",
       "21606          1895  \n",
       "23534          1895  \n",
       "38395          1895  \n",
       "40988          1896  \n",
       "18091          1896  \n",
       "38409          1896  \n",
       "41017          1896  \n",
       "30264          1896  \n",
       "38407          1896  \n",
       "41016          1896  \n",
       "40993          1896  \n",
       "38396          1896  \n",
       "38397          1896  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title','vote_count','popularity','release_year']].sort_values(by='release_year')[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Más variaciones a la limpieza y preprocesamiento\n",
    "\n",
    "Ahora vamos a utilizar el acercamiento en donde utilizamos el género, la productora, los directores, los actores, los años, la franquicia, el titulo y el original_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>The Double Life Of Veronique</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.661817</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29122</th>\n",
       "      <td>Lee Rock</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.807175</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29183</th>\n",
       "      <td>Robotrix</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.667275</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29265</th>\n",
       "      <td>Ultrà</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.266692</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29382</th>\n",
       "      <td>The Crucifer Of Blood</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.512575</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40957</th>\n",
       "      <td>Dragonheart: Battle For The Heartfire</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.794894</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40956</th>\n",
       "      <td>Drone</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8.413334</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40099</th>\n",
       "      <td>Asylum Of Darkness</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474061</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40995</th>\n",
       "      <td>What Happened To Monday</td>\n",
       "      <td>598.0</td>\n",
       "      <td>60.581223</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39595</th>\n",
       "      <td>The Bar</td>\n",
       "      <td>122.0</td>\n",
       "      <td>20.720113</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24436 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  vote_count  popularity  \\\n",
       "1011            The Double Life Of Veronique       154.0    9.661817   \n",
       "29122                               Lee Rock         3.0    1.807175   \n",
       "29183                               Robotrix         3.0    0.667275   \n",
       "29265                                  Ultrà        10.0    0.266692   \n",
       "29382                  The Crucifer Of Blood         5.0    0.512575   \n",
       "...                                      ...         ...         ...   \n",
       "40957  Dragonheart: Battle For The Heartfire        25.0    7.794894   \n",
       "40956                                  Drone        55.0    8.413334   \n",
       "40099                     Asylum Of Darkness         4.0    0.474061   \n",
       "40995                What Happened To Monday       598.0   60.581223   \n",
       "39595                                The Bar       122.0   20.720113   \n",
       "\n",
       "       release_year  \n",
       "1011           1991  \n",
       "29122          1991  \n",
       "29183          1991  \n",
       "29265          1991  \n",
       "29382          1991  \n",
       "...             ...  \n",
       "40957          2017  \n",
       "40956          2017  \n",
       "40099          2017  \n",
       "40995          2017  \n",
       "39595          2017  \n",
       "\n",
       "[24436 rows x 4 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franq = pd.read_csv('clean_data/franquicias.csv')\n",
    "id_franq = pd.read_csv('clean_data/franq_movies.csv')\n",
    "franq = id_franq.merge(franq).drop('id_franq',axis=1)\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "df = df.merge(franq,how='left')\n",
    "lista = list(df[['title','vote_count','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[:len(df) - 36000].index)\n",
    "df = df.drop(lista)\n",
    "df = df[['title','vote_count','popularity','release_year']][df.release_year > 1990].sort_values(by=['release_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "franq = pd.read_csv('clean_data/franquicias.csv')\n",
    "id_franq = pd.read_csv('clean_data/franq_movies.csv')\n",
    "franq = id_franq.merge(franq).drop('id_franq',axis=1)\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "df = df.merge(franq,how='left')\n",
    "lista = list(df[['title','vote_count','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[:len(df) - 36000].index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['title','vote_count','popularity','release_year']][df.release_year < 1990].sort_values(by=['release_year']).index)\n",
    "df = df.drop(lista)\n",
    "df = df[['id_peli',\t'title', 'original_language', 'release_year', 'franquicia']]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "genero = pd.read_csv('clean_data/generos.csv')\n",
    "id_genero = pd.read_csv('clean_data/gen_movies.csv')\n",
    "productora = pd.read_csv('clean_data/productoras.csv')\n",
    "id_productora = pd.read_csv('clean_data/prod_movies.csv')\n",
    "actor = pd.read_csv('clean_data/actores.csv')\n",
    "id_actor = pd.read_csv('clean_data/pers_movies.csv')\n",
    "director = pd.read_csv('clean_data/directores.csv')\n",
    "id_director = pd.read_csv('clean_data/dir_movies.csv')\n",
    "\n",
    "genero = id_genero.merge(genero).drop('id_gen',axis=1)\n",
    "productora = id_productora.merge(productora).drop('id_prod',axis=1)\n",
    "actor = id_actor.merge(actor).drop('id_act',axis=1)\n",
    "director = id_director.merge(director).drop('id_dir',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_list = []\n",
    "for x in productora.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        productora[productora.id_peli == x].loc[i].productora.replace(' ', '')\n",
    "        for i in productora[productora.id_peli == x].index\n",
    "    )\n",
    "    prod_list.append(lista_1)\n",
    "    \n",
    "act_list = []\n",
    "for x in actor.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        actor[actor.id_peli == x].loc[i].actor.replace(' ', '')\n",
    "        for i in actor[actor.id_peli == x].index\n",
    "    )\n",
    "    act_list.append(lista_1)\n",
    "    \n",
    "dir_list = []\n",
    "for x in director.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        director[director.id_peli == x].loc[i].director.replace(' ', '')\n",
    "        for i in director[director.id_peli == x].index\n",
    "    )\n",
    "    dir_list.append(lista_1)\n",
    "    \n",
    "gen_list = []\n",
    "for x in genero.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        genero[genero.id_peli == x].loc[i].genero.strip()\n",
    "        for i in genero[genero .id_peli == x].index\n",
    "    )\n",
    "    gen_list.append(lista_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "lista = ['id_peli']\n",
    "lista.extend(f'prod_{i}' for i in range(20))\n",
    "prod_df = pd.DataFrame(prod_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'dir_{i}' for i in range(41))\n",
    "dir_df = pd.DataFrame(dir_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'gen_{i}' for i in range(8))\n",
    "gen_df = pd.DataFrame(gen_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'act_{i}' for i in range(306))\n",
    "act_df = pd.DataFrame(act_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "act_df = act_df.iloc[:,:50]\n",
    "dir_df = dir_df.iloc[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productoras</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_peli</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [productoras]\n",
       "Index: []"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_df[prod_df.productoras == '%Pixar%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elenco</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_peli</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>TomHanks TimAllen DonRickles JimVarney Wallace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>TomHanks XanderBerkeley GabrielJarret KevinBac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TomHanks MykeltiWilliamson AaronMichaelLacey S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9800</th>\n",
       "      <td>TomHanks AnnaDeavereSmith MarySteenburgen Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>TomHanks DanaIvey RossMalinger DavidHydePierce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264269</th>\n",
       "      <td>MariyaFomina DmitriYendaltsev BorisPolunin Vik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370213</th>\n",
       "      <td>SonitaAlidazeh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75608</th>\n",
       "      <td>RobertGardner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282308</th>\n",
       "      <td>CharlesPrince GabrielleLange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258907</th>\n",
       "      <td>BarbaraHammer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42889 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    elenco\n",
       "id_peli                                                   \n",
       "862      TomHanks TimAllen DonRickles JimVarney Wallace...\n",
       "568      TomHanks XanderBerkeley GabrielJarret KevinBac...\n",
       "13       TomHanks MykeltiWilliamson AaronMichaelLacey S...\n",
       "9800     TomHanks AnnaDeavereSmith MarySteenburgen Anto...\n",
       "858      TomHanks DanaIvey RossMalinger DavidHydePierce...\n",
       "...                                                    ...\n",
       "264269   MariyaFomina DmitriYendaltsev BorisPolunin Vik...\n",
       "370213                                      SonitaAlidazeh\n",
       "75608                                        RobertGardner\n",
       "282308                        CharlesPrince GabrielleLange\n",
       "258907                                       BarbaraHammer\n",
       "\n",
       "[42889 rows x 1 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\3112353676.py:1: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  prod_df['productoras'] = pd.Series()\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\3112353676.py:18: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  act_df['elenco'] = pd.Series()\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\3112353676.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  act_df['elenco'] = pd.Series()\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\3112353676.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  act_df.iloc[:,i] = act_df.iloc[:,i].astype(str)\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\3112353676.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  act_df.loc[x,'elenco'] = ' '.join(lista_x)\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\3112353676.py:35: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  dir_df['cineastas'] = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "prod_df['productoras'] = pd.Series()\n",
    "for i in range(len(prod_df.columns)):\n",
    "    prod_df.iloc[:,i] = prod_df.iloc[:,i].astype(str)\n",
    "for x in prod_df.index:\n",
    "    lista_x = list(prod_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    prod_df.loc[x,'productoras'] = ' '.join(lista_x)\n",
    "for i in prod_df.columns:\n",
    "    if i != 'productoras':\n",
    "        prod_df.drop(i,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "act_df['elenco'] = pd.Series()\n",
    "for i in range(len(act_df.columns)):\n",
    "    act_df.iloc[:,i] = act_df.iloc[:,i].astype(str)\n",
    "for x in act_df.index:\n",
    "    lista_x = list(act_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    act_df.loc[x,'elenco'] = ' '.join(lista_x)\n",
    "for i in act_df.columns:\n",
    "    if i != 'elenco':\n",
    "        act_df.drop(i,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "dir_df['cineastas'] = pd.Series()\n",
    "for i in range(len(dir_df.columns)):\n",
    "    dir_df.iloc[:,i] = dir_df.iloc[:,i].astype(str)\n",
    "for x in dir_df.index:\n",
    "    lista_x = list(dir_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    dir_df.loc[x,'cineastas'] = ' '.join(lista_x)\n",
    "for i in dir_df.columns:\n",
    "    if i != 'cineastas':\n",
    "        dir_df.drop(i,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>word_bag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>ToyStoryCollection PixarAnimationStudios JohnL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>TeitlerFilm InterscopeCommunications JoeJohns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>GrumpyOldMenCollection WarnerBros. LancasterGa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>TwentiethCenturyFoxFilmCorporation ForestWhit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>SandollarProductions TouchstonePictures Charl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24757</th>\n",
       "      <td>404604</td>\n",
       "      <td>MadFilms ThirdEyePictures RaviUdyawar Akshaye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24758</th>\n",
       "      <td>420346</td>\n",
       "      <td>OopsDoughnutsProductions ShanraJ.Kehl TinaArn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24759</th>\n",
       "      <td>390959</td>\n",
       "      <td>BenRock ByrnePiven JamesGleason ChrisParnell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24760</th>\n",
       "      <td>111109</td>\n",
       "      <td>SineOlivia LavDiaz JoelTorre PerryDizon Solim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24761</th>\n",
       "      <td>67758</td>\n",
       "      <td>AmericanWorldPictures MarkL.Lester AdamBaldwi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24762 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                                           word_bag\n",
       "0          862  ToyStoryCollection PixarAnimationStudios JohnL...\n",
       "1         8844   TeitlerFilm InterscopeCommunications JoeJohns...\n",
       "2        15602  GrumpyOldMenCollection WarnerBros. LancasterGa...\n",
       "3        31357   TwentiethCenturyFoxFilmCorporation ForestWhit...\n",
       "4        11862   SandollarProductions TouchstonePictures Charl...\n",
       "...        ...                                                ...\n",
       "24757   404604   MadFilms ThirdEyePictures RaviUdyawar Akshaye...\n",
       "24758   420346   OopsDoughnutsProductions ShanraJ.Kehl TinaArn...\n",
       "24759   390959    BenRock ByrnePiven JamesGleason ChrisParnell...\n",
       "24760   111109   SineOlivia LavDiaz JoelTorre PerryDizon Solim...\n",
       "24761    67758   AmericanWorldPictures MarkL.Lester AdamBaldwi...\n",
       "\n",
       "[24762 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(prod_df.reset_index(),how='left').merge(dir_df.reset_index(),how='left').merge(act_df.reset_index(),how='left')\n",
    "df['word_bag'] = df[df.columns[4]].astype(str).apply(lambda x: x.replace(' ','')) + ' ' + df[df.columns[5]].astype(str) + ' ' + df[df.columns[6]].astype(str) + ' ' + df[df.columns[7]].astype(str)\n",
    "df['word_bag'] = df.word_bag.astype(str)\n",
    "df['word_bag'] = df.word_bag.apply(lambda x: x.replace('nan',''))\n",
    "for i in df.columns:\n",
    "    if i not in ['word_bag','id_peli']:\n",
    "        df.drop(i,axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157       \n",
       "Name: word_bag, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1157:1158].word_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_data/movies_model.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
