{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer Proyecto Individual en la Etapa de Labs en HENRY.\n",
    "\n",
    "#### Sección para la limpieza de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Consideraciones a tratar de la **Propuesta de Trabajo**:\n",
    "\n",
    "* Algunos campos, como belongs_to_collection, production_companies y otros (ver diccionario de datos) están anidados, esto es o bien tienen un diccionario o una lista como valores en cada fila, ¡deberán desanidarlos y unirlos al dataset de nuevo para hacer alguna de las consultas de la API! O bien buscar la manera de acceder a esos datos sin desanidarlos..\n",
    "\n",
    "* Los valores nulos de los campos revenue, budget deben ser rellenados por el número 0.\n",
    "\n",
    "* Los valores nulos del campo release date deben eliminarse.\n",
    "\n",
    "* De haber fechas, deberán tener el formato AAAA-mm-dd, además deberán crear la columna release_year donde extraerán el año de la fecha de estreno.\n",
    "\n",
    "* Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget, cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0.\n",
    "\n",
    "* Eliminar las columnas que no serán utilizadas, video,imdb_id,adult,original_title,poster_path y homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del dataset \"movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\3219681389.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv('Data/movies_dataset.csv')\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\3219681389.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['row_count'] = df.sort_values(by=['title','release_date'],ascending=False).groupby(['title']).cumcount()+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas eliminadas del dataset por no contener información relevante:            id_peli title                            budget original_language  \\\n",
      "17925  1997-08-20   NaN  /ff9qCepilowshEtG2GYWwzt2bs4.jpg             104.0   \n",
      "27013  2012-09-29   NaN  /zV8bHuSL6WXoD6FWogP9j4x80bL.jpg              68.0   \n",
      "32768  2014-01-01   NaN  /zaSf5OG7V8X8gqFvly88zDdRm46.jpg              82.0   \n",
      "\n",
      "      release_date  revenue  runtime production_companies  \\\n",
      "17925            1      NaN      NaN                False   \n",
      "27013           12      NaN      NaN                False   \n",
      "32768           22      NaN      NaN                False   \n",
      "\n",
      "      belongs_to_collection production_countries  \\\n",
      "17925              0.065736                  6.0   \n",
      "27013              1.931659                  7.0   \n",
      "32768              2.185485                  4.3   \n",
      "\n",
      "                                                  genres  overview  \\\n",
      "17925  [{'name': 'Carousel Productions', 'id': 11176}...  Released   \n",
      "27013  [{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...  Released   \n",
      "32768  [{'name': 'Odyssey Media', 'id': 17161}, {'nam...  Released   \n",
      "\n",
      "                  popularity spoken_languages status tagline  vote_average  \\\n",
      "17925                    NaN              NaN    NaN     NaN           NaN   \n",
      "27013                    NaN              NaN    NaN     NaN           NaN   \n",
      "32768  Beware Of Frost Bites              NaN    NaN     NaN           NaN   \n",
      "\n",
      "       vote_count  \n",
      "17925         NaN  \n",
      "27013         NaN  \n",
      "32768         NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\3219681389.py:76: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  movies_df['return'] = pd.Series()\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\3219681389.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_df['return'][i] = x[i]/y[i] if y[i] != 0 else 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>return</th>\n",
       "      <th>original_language</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>12.451801</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>81.0</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>4.043035</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting To Exhale</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>5.090760</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father Of The Bride Part Ii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41760</th>\n",
       "      <td>222848</td>\n",
       "      <td>Caged Heat 3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.661558</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>111109</td>\n",
       "      <td>Century Of Birthing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tl</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41762</th>\n",
       "      <td>67758</td>\n",
       "      <td>Betrayal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-08-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.903007</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>227506</td>\n",
       "      <td>Satan Triumphant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1917</td>\n",
       "      <td>1917-10-21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41764</th>\n",
       "      <td>461257</td>\n",
       "      <td>Queerama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.163015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41765 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                        title      budget      revenue  \\\n",
       "0          862                    Toy Story  30000000.0  373554033.0   \n",
       "1         8844                      Jumanji  65000000.0  262797249.0   \n",
       "2        15602             Grumpier Old Men         0.0          0.0   \n",
       "3        31357            Waiting To Exhale  16000000.0   81452156.0   \n",
       "4        11862  Father Of The Bride Part Ii         0.0   76578911.0   \n",
       "...        ...                          ...         ...          ...   \n",
       "41760   222848              Caged Heat 3000         0.0          0.0   \n",
       "41761   111109          Century Of Birthing         0.0          0.0   \n",
       "41762    67758                     Betrayal         0.0          0.0   \n",
       "41763   227506             Satan Triumphant         0.0          0.0   \n",
       "41764   461257                     Queerama         0.0          0.0   \n",
       "\n",
       "          return original_language  release_year release_date  runtime  \\\n",
       "0      12.451801                en          1995   1995-10-30     81.0   \n",
       "1       4.043035                en          1995   1995-12-15    104.0   \n",
       "2       0.000000                en          1995   1995-12-22    101.0   \n",
       "3       5.090760                en          1995   1995-12-22    127.0   \n",
       "4       0.000000                en          1995   1995-02-10    106.0   \n",
       "...          ...               ...           ...          ...      ...   \n",
       "41760   0.000000                en          1995   1995-01-01     85.0   \n",
       "41761   0.000000                tl          2011   2011-11-17    360.0   \n",
       "41762   0.000000                en          2003   2003-08-01     90.0   \n",
       "41763   0.000000                en          1917   1917-10-21     87.0   \n",
       "41764   0.000000                en          2017   2017-06-09     75.0   \n",
       "\n",
       "       popularity  vote_average  vote_count  \n",
       "0       21.946943           7.7      5415.0  \n",
       "1       17.015539           6.9      2413.0  \n",
       "2       11.712900           6.5        92.0  \n",
       "3        3.859495           6.1        34.0  \n",
       "4        8.387519           5.7       173.0  \n",
       "...           ...           ...         ...  \n",
       "41760    0.661558           3.5         1.0  \n",
       "41761    0.178241           9.0         3.0  \n",
       "41762    0.903007           3.8         6.0  \n",
       "41763    0.003503           0.0         0.0  \n",
       "41764    0.163015           0.0         0.0  \n",
       "\n",
       "[41765 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos el dataset hacia un dataframe en python.\n",
    "movies_df = pd.read_csv('Data/movies_dataset.csv')\n",
    "\n",
    "# Seleccionamos las columnas que necesitamos y eliminamos las que nos piden: video,imdb_id,adult,original_title,poster_path,homepage. Y renombramos algunas.\n",
    "movies_df = movies_df[['id', 'title', 'budget', 'original_language', 'release_date', 'revenue', 'runtime', 'production_companies',  \n",
    "        'belongs_to_collection', 'production_countries', 'genres', 'overview', 'popularity',\n",
    "        'spoken_languages', 'status', 'tagline', 'vote_average', 'vote_count']]\n",
    "movies_df.columns = ['id_peli', 'title', 'budget', 'original_language', 'release_date', 'revenue', 'runtime', 'production_companies',  \n",
    "        'belongs_to_collection', 'production_countries', 'genres', 'overview', 'popularity',\n",
    "        'spoken_languages', 'status', 'tagline', 'vote_average', 'vote_count']\n",
    "\n",
    "# Eliminamos los campos nulos de la columna \"release_date\".\n",
    "movies_df = movies_df.dropna(subset=['release_date']).reset_index(drop=True)\n",
    "\n",
    "# Eliminamos películas duplicadas. Para este caso, tomamos las películas duplicadas con fecha de lanzamiento más reciente.\n",
    "df = movies_df[movies_df.title.isin(list(movies_df[movies_df.title.duplicated()].title))]\n",
    "df['row_count'] = df.sort_values(by=['title','release_date'],ascending=False).groupby(['title']).cumcount()+1\n",
    "index = list(df[df.row_count > 1].id_peli)\n",
    "movies_df = movies_df.set_index('id_peli')\n",
    "movies_df = movies_df.drop(index).reset_index()\n",
    "\n",
    "# Transformando los datos del \"id\" de película a enteros: Me di cuenta mediante este proceso de que existen 3 \"id's\" que son fechas, por lo que eliminé dichas filas.\n",
    "index = []\n",
    "for i in range(len(movies_df)):\n",
    "    try:\n",
    "        movies_df.loc[i,['id_peli']] = int(movies_df.id_peli[i])\n",
    "    except ValueError:\n",
    "        index.append(i)\n",
    "\n",
    "# Visualizamos las filas que no contienen datos relevantes: index = [19714,29472,35543]      \n",
    "print('Filas eliminadas del dataset por no contener información relevante: ',movies_df.loc[index])\n",
    "\n",
    "# Eliminamos las filas.\n",
    "movies_df = movies_df.drop(index)\n",
    "\n",
    "# Seleccionamos las películas con \"status\" = 'Released'.\n",
    "movies_df = movies_df[movies_df.status == 'Released']\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Por último vamos a examinar si existen filas duplicadas en nuestro dataframe.\n",
    "# Utilizamos primeramente el método drop_duplicates().\n",
    "movies_df = movies_df.drop_duplicates()\n",
    "\n",
    "# Después buscamos si existen \"id's\" repetidos después del método.\n",
    "dfx = movies_df.groupby('id_peli')['id_peli'].count() > 1\n",
    "dfx = pd.DataFrame(dfx)\n",
    "index = list(dfx[dfx.id_peli == True].index)\n",
    "\n",
    "# Creamos un DF temporal con el objetivo de obtener las filas con 'id's' duplicados.\n",
    "dfx = pd.DataFrame()\n",
    "for i in index:\n",
    "    dfx = pd.concat([dfx,movies_df[movies_df.id_peli == i]])\n",
    "\n",
    "# Tomamos las filas duplicadas que están en segundo lugar y las eliminamos.\n",
    "index = list(dfx[1::2].index)\n",
    "movies_df = movies_df.drop(index).reset_index(drop=True)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Rellenar valores nulos en los campos \"budget\" y \"revenue\" por 0.\n",
    "movies_df['revenue'] = movies_df.revenue.fillna(0)\n",
    "movies_df['budget'] = movies_df.budget.fillna(0)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# De haber fechas, deberán tener el formato AAAA-mm-dd, además, deberán crear la columna \"release_year\", donde extraerán el año de la fecha de estreno.\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df['release_date'])\n",
    "movies_df['release_year'] = movies_df['release_date'].apply(lambda x: x.year)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget, cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0.\n",
    "movies_df['budget'] = movies_df.budget.astype(float)\n",
    "def returns(x,y):\n",
    "    movies_df['return'] = pd.Series()\n",
    "    for i in range(len(x)):\n",
    "        movies_df['return'][i] = x[i]/y[i] if y[i] != 0 else 0\n",
    "returns(movies_df.revenue,movies_df.budget)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Creamos una función lambda que nos va a ayudar a pasar los strings a listas de diccionarios.\n",
    "a_lista = lambda x: eval(x)\n",
    "\n",
    "# Separamos las columnas con sus respectivos \"id_peli\" en 5 diferentes DF's.\n",
    "df1 = movies_df[['id_peli','production_companies']].reset_index(drop=True)\n",
    "df2 = movies_df[['id_peli','belongs_to_collection']].reset_index(drop=True)\n",
    "df3 = movies_df[['id_peli','production_countries']].reset_index(drop=True)\n",
    "df4 = movies_df[['id_peli','genres']].reset_index(drop=True)\n",
    "df5 = movies_df[['id_peli','spoken_languages']].reset_index(drop=True)\n",
    "\n",
    "# Ahora que ya hemos utilizado las columnas que necesitamos para desanidar las columnas anidadas, podemos eliminarlas de nuestro dataframe de películas, ya que la información está en\n",
    "# nuevos dataframes.\n",
    "movies_df = movies_df[['id_peli', 'title', 'budget', 'revenue', 'return', 'original_language', 'release_year', 'release_date', 'runtime', 'popularity', 'vote_average', 'vote_count']]\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Convertimos los campos anidados de nuestro dataset inicial, de strings a listas de diccionarios. En total son 5 columnas anidadas.\n",
    "df1['production_companies'] = df1['production_companies'].apply(a_lista)\n",
    "\n",
    "df2 = df2.dropna().reset_index(drop=True)\n",
    "df2['belongs_to_collection'] = df2['belongs_to_collection'].apply(a_lista)\n",
    "\n",
    "df3['production_countries'] = df3['production_countries'].apply(a_lista)\n",
    "\n",
    "df4['genres'] = df4['genres'].apply(a_lista)\n",
    "\n",
    "df5 = df5.dropna().reset_index(drop=True)\n",
    "df5['spoken_languages'] = df5['spoken_languages'].apply(a_lista)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Dejamos la columna \"release_date\" como datetime. Y capitalizamos las letras de los titulos para homogenizar.\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df.release_date)\n",
    "movies_df['title'] = movies_df.title.apply(lambda x: x.title())\n",
    "movies_df['original_language'] = movies_df.original_language.astype(str)\n",
    "movies_df['original_language'] = movies_df.original_language.apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "if not os.path.exists('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/'):\n",
    "    os.mkdir('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/')\n",
    "movies_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/movies.csv',index=False)\n",
    "\n",
    "# Visualizamos el dataframe.\n",
    "pd.read_csv('clean_data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>production_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41760</th>\n",
       "      <td>222848</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>111109</td>\n",
       "      <td>[{'iso_3166_1': 'PH', 'name': 'Philippines'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41762</th>\n",
       "      <td>67758</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>227506</td>\n",
       "      <td>[{'iso_3166_1': 'RU', 'name': 'Russia'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41764</th>\n",
       "      <td>461257</td>\n",
       "      <td>[{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_peli                               production_countries\n",
       "0         862  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "1        8844  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "2       15602  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "3       31357  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "4       11862  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "...       ...                                                ...\n",
       "41760  222848  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "41761  111109      [{'iso_3166_1': 'PH', 'name': 'Philippines'}]\n",
       "41762   67758  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "41763  227506           [{'iso_3166_1': 'RU', 'name': 'Russia'}]\n",
       "41764  461257   [{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]\n",
       "\n",
       "[41765 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desanidado de columnas y creación de 5 nuevos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================================================================\n",
    "# Creación del DF \"productoras_df\" y del DF \"id_productoras_df\".\n",
    "# Lo que sigue es obtener el dataframe de las productoras asociadas a cada película.\n",
    "# sourcery skip: use-fstring-for-concatenation\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df1)):\n",
    "    df = pd.DataFrame(df1.production_companies[i])\n",
    "    df['id'] = df1.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "dfx.columns = ['productora','id_peli']\n",
    "\n",
    "# Ahora creamos el dataframe de las productoras únicas con un id único.\n",
    "productoras_df = dfx.productora.unique()\n",
    "productoras_df = pd.DataFrame(productoras_df,columns=['productora'])\n",
    "productoras_df = productoras_df.reset_index()\n",
    "productoras_df.columns = ['id_prod','productora']\n",
    "productoras_df['id_prod'] = productoras_df.id_prod.apply(lambda x: x+1)\n",
    "productoras_df['productora'] = productoras_df.productora.apply(lambda x: x.title())\n",
    "\n",
    "\n",
    "# Por último agregamos los \"id's\" de las productoras al dataframe de las productoras asociadas a películas y eliminamos la columna que contiene el nombre de la productora para reducir el \n",
    "# uso de memoria.\n",
    "dfx = dfx.merge(productoras_df)\n",
    "dfx = dfx.drop('productora',axis=1)\n",
    "id_productoras_df = dfx\n",
    "id_productoras_df['id_peli'] = id_productoras_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "productoras_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/productoras.csv',index=False)\n",
    "id_productoras_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/prod_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"franquicias_df\" y del DF \"id_franquicias_df\"\n",
    "# Obtenemos el dataframe de las franquicias asociadas a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df2)):\n",
    "    df = pd.DataFrame([df2.belongs_to_collection[i]])\n",
    "    df['id'] = df2.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de las franquicias únicas con un id único.\n",
    "dfx = dfx.drop(['poster_path','backdrop_path'],axis=1)\n",
    "dfx.columns = ['id_peli','franquicia']\n",
    "franquicias_df = dfx.franquicia.unique()\n",
    "franquicias_df = pd.DataFrame(franquicias_df,columns=['franquicia']).reset_index()\n",
    "franquicias_df.columns = ['id_franq','franquicia']\n",
    "franquicias_df['id_franq'] = franquicias_df.id_franq.apply(lambda x: x+1)\n",
    "franquicias_df = franquicias_df[['id_franq','franquicia']]\n",
    "franquicias_df['franquicia'] = franquicias_df.franquicia.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de las franquicias al dataframe de las franquicias asociadas a películas y eliminamos la columna que contiene el nombre de la franquicia para reducir el \n",
    "# uso de memoria.\n",
    "id_franquicias_df = dfx.merge(franquicias_df)\n",
    "id_franquicias_df = id_franquicias_df.drop(['franquicia'],axis=1)\n",
    "id_franquicias_df['id_peli'] = id_franquicias_df.id_peli.astype(int) \n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "franquicias_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/franquicias.csv',index=False)\n",
    "id_franquicias_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/franq_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"paises_df\" y del DF \"id_paises_df\"\n",
    "# Obtenemos el dataframe de los países asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df3)):\n",
    "    df = pd.DataFrame(df3.production_countries[i])\n",
    "    df['id'] = df3.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los países únicos con un id único.\n",
    "dfx.columns = ['iso_3166_1','pais','id_peli']\n",
    "dfx['dummy'] = dfx.iso_3166_1 + ' ' + dfx.pais\n",
    "paises_df = dfx.dummy.unique()\n",
    "paises_df = pd.DataFrame(paises_df,columns=['pais']).reset_index()\n",
    "paises_df.columns = ['id_pais','pais']\n",
    "paises_df['abrev'] = paises_df.pais.apply(lambda x: x[:2])\n",
    "paises_df['pais'] = paises_df.pais.apply(lambda x: x[3:])\n",
    "paises_df['id_pais'] = paises_df.id_pais.apply(lambda x: x + 1)\n",
    "paises_df['pais'] = paises_df.pais.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los países al dataframe de los países asociadas a películas y eliminamos la columna que contiene el nombre del país para reducir el \n",
    "# uso de memoria.\n",
    "dfx['pais'] = dfx.pais.apply(lambda x: x.title())\n",
    "id_paises_df = dfx.merge(paises_df)\n",
    "id_paises_df = id_paises_df.drop(['iso_3166_1','pais','dummy','abrev'],axis=1)\n",
    "id_paises_df['id_peli'] = id_paises_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "paises_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/paises.csv',index=False)\n",
    "id_paises_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/pais_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"generos_df\" y del DF \"id_generos_df\"\n",
    "# Obtenemos el dataframe de los generos asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df4)):\n",
    "    df = pd.DataFrame(df4.genres[i])\n",
    "    df['id'] = df4.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los generos únicos con un id único.\n",
    "dfx.columns = ['id_peli','genero']\n",
    "generos_df = pd.DataFrame(dfx.genero.unique(),columns=['genero']).reset_index()\n",
    "generos_df.columns = ['id_gen','genero']\n",
    "generos_df['id_gen'] = generos_df.id_gen.apply(lambda x: x + 1)\n",
    "generos_df['genero'] = generos_df.genero.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los generos al dataframe de los generos asociadas a películas y eliminamos la columna que contiene el nombre del genero para reducir el \n",
    "# uso de memoria.\n",
    "id_generos_df = dfx.merge(generos_df)\n",
    "id_generos_df = id_generos_df.drop(['genero'],axis=1)\n",
    "id_generos_df['id_peli'] = id_generos_df.id_peli.astype(int)\n",
    "id_generos_df.columns = ['id_peli','id_gen']\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "generos_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/generos.csv',index=False)\n",
    "id_generos_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/gen_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"lenguajes_df\" y del DF \"id_lenguajes_df\"\n",
    "# Obtenemos el dataframe de los lenguajes asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df5)):\n",
    "    df = pd.DataFrame(df5.spoken_languages[i])\n",
    "    df['id'] = df5.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los lenguajes únicos con un id único.\n",
    "dfx.columns = ['iso_639_1','lenguaje','id_peli']\n",
    "dfx['dummy'] = dfx.iso_639_1 + ' ' + dfx.lenguaje\n",
    "lenguajes_df = pd.DataFrame(dfx.dummy.unique(),columns=['lenguaje'])\n",
    "lenguajes_df['abrev'] = lenguajes_df.lenguaje.apply(lambda x: x[:2])\n",
    "lenguajes_df['lenguaje'] = lenguajes_df.lenguaje.apply(lambda x: x[3:])\n",
    "lenguajes_df = lenguajes_df.reset_index()\n",
    "lenguajes_df.columns = ['id_leng','lenguaje','abrev']\n",
    "lenguajes_df['id_leng'] = lenguajes_df.id_leng.apply(lambda x: x + 1)\n",
    "lenguajes_df = lenguajes_df[lenguajes_df.abrev.isin(list(movies_df.original_language.unique()))]\n",
    "lenguajes_df['lenguaje'] = lenguajes_df.lenguaje.apply(lambda x: x.title())\n",
    "lenguajes_df['abrev'] = lenguajes_df.abrev.apply(lambda x: x.lower())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los lenguajes al dataframe de los lenguajes asociadas a películas y eliminamos la columna que contiene el nombre del lenguaje para reducir el \n",
    "# uso de memoria.\n",
    "id_lenguajes_df = dfx.merge(lenguajes_df)\n",
    "id_lenguajes_df = id_lenguajes_df.drop(['iso_639_1','lenguaje','dummy','abrev'],axis=1)\n",
    "id_lenguajes_df['id_peli'] = id_lenguajes_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "lenguajes_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/lenguajes.csv',index=False)\n",
    "id_lenguajes_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/leng_movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_pais</th>\n",
       "      <th>pais</th>\n",
       "      <th>abrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>United States Of America</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>AQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>158</td>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159</td>\n",
       "      <td>Honduras</td>\n",
       "      <td>HN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>GN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_pais                      pais abrev\n",
       "0          1  United States Of America    US\n",
       "1          2                   Germany    DE\n",
       "2          3            United Kingdom    GB\n",
       "3          4                    France    FR\n",
       "4          5                     Italy    IT\n",
       "..       ...                       ...   ...\n",
       "155      156                Antarctica    AQ\n",
       "156      157                 Gibraltar    GI\n",
       "157      158         Brunei Darussalam    BN\n",
       "158      159                  Honduras    HN\n",
       "159      160                    Guinea    GN\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paises_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>id_pais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45552</th>\n",
       "      <td>132873</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45553</th>\n",
       "      <td>16403</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45554</th>\n",
       "      <td>277690</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45555</th>\n",
       "      <td>321530</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45556</th>\n",
       "      <td>160372</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45557 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli  id_pais\n",
       "0          862        1\n",
       "1         8844        1\n",
       "2        15602        1\n",
       "3        31357        1\n",
       "4        11862        1\n",
       "...        ...      ...\n",
       "45552   132873      156\n",
       "45553    16403      157\n",
       "45554   277690      158\n",
       "45555   321530      159\n",
       "45556   160372      160\n",
       "\n",
       "[45557 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_paises_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del dataset \"credits.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================================================================\n",
    "# Ingresamos el dataset.\n",
    "credits_df = pd.read_csv('Data/credits.csv')\n",
    "\n",
    "# Dividimos el dataset en dos dataframe's\n",
    "elenco_df = credits_df[['id','cast']]\n",
    "productores_df = credits_df[['id','crew']]\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Eliminamos los nan, reestablecemos el índice y convertimos las strings en listas de diccionarios de ambos datasets.\n",
    "productores_df = productores_df.dropna().reset_index(drop=True)\n",
    "productores_df['crew'] = productores_df['crew'].apply(a_lista)\n",
    "elenco_df = elenco_df.dropna().reset_index(drop=True)\n",
    "elenco_df['cast'] = elenco_df['cast'].apply(a_lista)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Desanidamos la columna \"crew\".\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(productores_df)):\n",
    "    df = pd.DataFrame(productores_df.crew[i])\n",
    "    if not df.empty:\n",
    "        df = df[['id', 'job', 'name']][df.job == 'Director']\n",
    "        df = df.drop('job',axis=1)\n",
    "        df['id'] = productores_df.id[i]\n",
    "        dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Obtenemos solo los directores del dataset \"credits.csv\" y la tabla que asocia películas con directores.\n",
    "id_directores_df = dfx\n",
    "id_directores_df.columns = ['id_peli', 'director']\n",
    "directores_df = id_directores_df.director.unique()\n",
    "directores_df = pd.DataFrame(directores_df).reset_index()\n",
    "directores_df.columns = ['id_dir','director']\n",
    "directores_df['id_dir'] = directores_df.id_dir.apply(lambda x: x + 1)\n",
    "directores_df['director'] = directores_df.director.apply(lambda x: x.title())\n",
    "id_directores_df = id_directores_df.merge(directores_df).drop('director',axis=1)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Desanidamos la columna \"cast\" y creamos el dataframe de personajes.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(elenco_df)):\n",
    "    df = pd.DataFrame(elenco_df.cast[i])\n",
    "    if not df.empty:\n",
    "        df = df[['id', 'name']]\n",
    "        df['id'] = elenco_df.id[i]\n",
    "        dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "dfx.columns = ['id_peli', 'actor']\n",
    "id_personajes_actores_df = dfx\n",
    "\n",
    "# También creamos el dataset de actores con el mismo objetivo.\n",
    "dfx = id_personajes_actores_df.actor.unique()\n",
    "dfx = pd.DataFrame(dfx).reset_index()\n",
    "dfx.columns = ['id_act','actor']\n",
    "dfx['id_act'] = dfx.id_act.apply(lambda x: x + 1)\n",
    "dfx['actor'] = dfx.actor.apply(lambda x: x.title())\n",
    "actores_df = dfx\n",
    "\n",
    "# Ahora eliminamos la columna de actores y de personajes para solo dejar \"id's\"\n",
    "id_personajes_actores_df = id_personajes_actores_df.merge(actores_df)\n",
    "id_personajes_actores_df = id_personajes_actores_df.drop(['actor'],axis=1)\n",
    "id_personajes_actores_df\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creamos los archivos .csv de los dataframe's resultantes.\n",
    "directores_df.to_csv('clean_data/directores.csv',index=False)\n",
    "id_directores_df.to_csv('clean_data/dir_movies.csv',index=False)\n",
    "actores_df.to_csv('clean_data/actores.csv',index=False)\n",
    "id_personajes_actores_df.to_csv('clean_data/pers_movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección de desarrollo del dataset para el modelo de recomendación\n",
    "\n",
    "Esta parte de la limpieza se desarrolló a la par del desarrollo del EDA y del modelo de ML. Parte del código que vamos a utilizar para generar esta parte de la limpieza la obtuvimos del EDA y del ML_model. Preprocesamiento de datos y más limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\378662076.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lista = list(df[['id_peli','title','vote_count', 'vote_average','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[df.vote_count >= 15].id_peli)\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\378662076.py:75: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  act_df['elenco'] = pd.Series()\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\378662076.py:92: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  dir_df['cineastas'] = pd.Series()\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\378662076.py:109: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  gen_df['genero'] = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "# sourcery skip: use-contextlib-suppress\n",
    "franq = pd.read_csv('clean_data/franquicias.csv')\n",
    "id_franq = pd.read_csv('clean_data/franq_movies.csv')\n",
    "franq = id_franq.merge(franq).drop('id_franq',axis=1)\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "df = df.merge(franq,how='left')\n",
    "lista = list(df[['title','vote_count','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[:len(df) - 36000].index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['title','vote_count','popularity','release_year']][df.release_year < 1975].sort_values(by=['release_year']).index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['id_peli','title','vote_count', 'vote_average','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[df.vote_count >= 15].id_peli)\n",
    "df = df[df.id_peli.apply(lambda x: x in lista)].reset_index(drop=True)\n",
    "df = df[['id_peli',\t'title', 'franquicia']]\n",
    "\n",
    "genero = pd.read_csv('clean_data/generos.csv')\n",
    "id_genero = pd.read_csv('clean_data/gen_movies.csv')\n",
    "productora = pd.read_csv('clean_data/productoras.csv')\n",
    "id_productora = pd.read_csv('clean_data/prod_movies.csv')\n",
    "actor = pd.read_csv('clean_data/actores.csv')\n",
    "id_actor = pd.read_csv('clean_data/pers_movies.csv')\n",
    "director = pd.read_csv('clean_data/directores.csv')\n",
    "id_director = pd.read_csv('clean_data/dir_movies.csv')\n",
    "\n",
    "genero = id_genero.merge(genero).drop('id_gen',axis=1)\n",
    "productora = id_productora.merge(productora).drop('id_prod',axis=1)\n",
    "actor = id_actor.merge(actor).drop('id_act',axis=1)\n",
    "director = id_director.merge(director).drop('id_dir',axis=1)\n",
    "\n",
    "\n",
    "# Sección para crear los dataframes que vamos a utilizar en nuestra bolsa de palabras.\n",
    "act_list = []\n",
    "for x in actor.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        actor[actor.id_peli == x].loc[i].actor.replace(' ', '')\n",
    "        for i in actor[actor.id_peli == x].index\n",
    "    )\n",
    "    act_list.append(lista_1)\n",
    "    \n",
    "dir_list = []\n",
    "for x in director.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        director[director.id_peli == x].loc[i].director.replace(' ', '')\n",
    "        for i in director[director.id_peli == x].index\n",
    "    )\n",
    "    dir_list.append(lista_1)\n",
    "    \n",
    "gen_list = []\n",
    "for x in genero.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        genero[genero.id_peli == x].loc[i].genero.strip()\n",
    "        for i in genero[genero.id_peli == x].index\n",
    "    )\n",
    "    gen_list.append(lista_1)\n",
    "    \n",
    "    \n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'dir_{i}' for i in range(41))\n",
    "dir_df = pd.DataFrame(dir_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'gen_{i}' for i in range(8))\n",
    "gen_df = pd.DataFrame(gen_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'act_{i}' for i in range(306))\n",
    "act_df = pd.DataFrame(act_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "\n",
    "\n",
    "# Sección para unir los valores de las columnas por filas.\n",
    "act_df['elenco'] = pd.Series()\n",
    "for i in range(len(act_df.columns)):\n",
    "    act_df.iloc[:,i] = act_df.iloc[:,i].astype(str)\n",
    "for x in act_df.index:\n",
    "    lista_x = list(act_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    act_df.loc[x,'elenco'] = ' '.join(lista_x)\n",
    "for i in act_df.columns:\n",
    "    if i != 'elenco':\n",
    "        act_df.drop(i,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "dir_df['cineastas'] = pd.Series()\n",
    "for i in range(len(dir_df.columns)):\n",
    "    dir_df.iloc[:,i] = dir_df.iloc[:,i].astype(str)\n",
    "for x in dir_df.index:\n",
    "    lista_x = list(dir_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    dir_df.loc[x,'cineastas'] = ' '.join(lista_x)\n",
    "for i in dir_df.columns:\n",
    "    if i != 'cineastas':\n",
    "        dir_df.drop(i,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "gen_df['genero'] = pd.Series()\n",
    "for i in range(len(gen_df.columns)):\n",
    "    gen_df.iloc[:,i] = gen_df.iloc[:,i].astype(str)\n",
    "for x in gen_df.index:\n",
    "    lista_x = list(gen_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    gen_df.loc[x,'genero'] = ' '.join(lista_x)\n",
    "for i in gen_df.columns:\n",
    "    if i != 'genero':\n",
    "        gen_df.drop(i,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elenco</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_peli</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>TomHanks TimAllen DonRickles JimVarney Wallace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>TomHanks XanderBerkeley GabrielJarret KevinBac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TomHanks MykeltiWilliamson AaronMichaelLacey S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9800</th>\n",
       "      <td>TomHanks AnnaDeavereSmith MarySteenburgen Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>TomHanks DanaIvey RossMalinger DavidHydePierce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264269</th>\n",
       "      <td>MariyaFomina DmitriYendaltsev BorisPolunin Vik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370213</th>\n",
       "      <td>SonitaAlidazeh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75608</th>\n",
       "      <td>RobertGardner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282308</th>\n",
       "      <td>CharlesPrince GabrielleLange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258907</th>\n",
       "      <td>BarbaraHammer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42889 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    elenco\n",
       "id_peli                                                   \n",
       "862      TomHanks TimAllen DonRickles JimVarney Wallace...\n",
       "568      TomHanks XanderBerkeley GabrielJarret KevinBac...\n",
       "13       TomHanks MykeltiWilliamson AaronMichaelLacey S...\n",
       "9800     TomHanks AnnaDeavereSmith MarySteenburgen Anto...\n",
       "858      TomHanks DanaIvey RossMalinger DavidHydePierce...\n",
       "...                                                    ...\n",
       "264269   MariyaFomina DmitriYendaltsev BorisPolunin Vik...\n",
       "370213                                      SonitaAlidazeh\n",
       "75608                                        RobertGardner\n",
       "282308                        CharlesPrince GabrielleLange\n",
       "258907                                       BarbaraHammer\n",
       "\n",
       "[42889 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_peli', 'title', 'franquicia', 'genero', 'cineastas', 'elenco'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merge(gen_df.reset_index(),how='left').merge(dir_df.reset_index(),how='left').merge(act_df.reset_index(),how='left').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24508\\3325095180.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lista = list(df[['id_peli','title','vote_count', 'vote_average','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[df.vote_count >= 15].id_peli)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        TomHanks TimAllen DonRickles JimVarney Wallace...\n",
       "1        RobinWilliams JonathanHyde KirstenDunst Bradle...\n",
       "2        WalterMatthau JackLemmon Ann-Margret SophiaLor...\n",
       "3        WhitneyHouston AngelaBassett LorettaDevine Lel...\n",
       "4        SteveMartin DianeKeaton MartinShort KimberlyWi...\n",
       "                               ...                        \n",
       "15071    RobertKing ChrisO'Dowd JessicaWilliams Matthew...\n",
       "15072    MichaelFilipowich MerwinMondesir KristopherHig...\n",
       "15073    TchékyKaryo RufusSewell JimCarter JamesFrain J...\n",
       "15074                                                  NaN\n",
       "15075    GaryCole ChristyCarlsonRomano DesmondCampbell ...\n",
       "Name: elenco, Length: 15076, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sourcery skip: use-fstring-for-concatenation\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "df = df.merge(franq,how='left')\n",
    "lista = list(df[['title','vote_count','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[:len(df) - 36000].index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['title','vote_count','popularity','release_year']][df.release_year < 1975].sort_values(by=['release_year']).index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['id_peli','title','vote_count', 'vote_average','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[df.vote_count >= 15].id_peli)\n",
    "df = df[df.id_peli.apply(lambda x: x in lista)].reset_index(drop=True)\n",
    "df = df[['id_peli',\t'title', 'franquicia']]\n",
    "\n",
    "df = df.merge(gen_df.reset_index(),how='left').merge(dir_df.reset_index(),how='left').merge(act_df.reset_index(),how='left')\n",
    "x = df.columns\n",
    "title = df[df.columns[1]].astype(str)\n",
    "franquicia = df[df.columns[2]].astype(str).apply(lambda x: x.replace(' ',''))\n",
    "genero = df[df.columns[3]].astype(str)\n",
    "director = df[df.columns[4]].astype(str)\n",
    "actor = df[df.columns[5]].astype(str)\n",
    "# df['word_bag'] =  title + ' ' + franquicia + ' ' + genero + ' ' + director + ' ' + actor\n",
    "# df['word_bag'] = df.word_bag.astype(str)\n",
    "# df['word_bag'] = df.word_bag.apply(lambda x: x.replace('nan',''))\n",
    "# for i in df.columns:\n",
    "#     if i not in ['word_bag','id_peli','title']:\n",
    "#         df.drop(i,axis=1,inplace=True)\n",
    "# df\n",
    "df[df.columns[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_data/movies_model.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
