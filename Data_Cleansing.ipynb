{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer Proyecto Individual en la Etapa de Labs en HENRY.\n",
    "\n",
    "#### Sección para la limpieza de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Consideraciones a tratar en este paso:\n",
    "\n",
    "* Algunos campos, como belongs_to_collection, production_companies y otros (ver diccionario de datos) están anidados, esto es o bien tienen un diccionario o una lista como valores en cada fila, ¡deberán desanidarlos y unirlos al dataset de nuevo para hacer alguna de las consultas de la API! O bien buscar la manera de acceder a esos datos sin desanidarlos..\n",
    "\n",
    "* Los valores nulos de los campos revenue, budget deben ser rellenados por el número 0.\n",
    "\n",
    "* Los valores nulos del campo release date deben eliminarse.\n",
    "\n",
    "* De haber fechas, deberán tener el formato AAAA-mm-dd, además deberán crear la columna release_year donde extraerán el año de la fecha de estreno.\n",
    "\n",
    "* Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget, cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0.\n",
    "\n",
    "* Eliminar las columnas que no serán utilizadas, video,imdb_id,adult,original_title,poster_path y homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del dataset \"movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25160\\3219681389.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv('Data/movies_dataset.csv')\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25160\\3219681389.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['row_count'] = df.sort_values(by=['title','release_date'],ascending=False).groupby(['title']).cumcount()+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas eliminadas del dataset por no contener información relevante:            id_peli title                            budget original_language  \\\n",
      "17925  1997-08-20   NaN  /ff9qCepilowshEtG2GYWwzt2bs4.jpg             104.0   \n",
      "27013  2012-09-29   NaN  /zV8bHuSL6WXoD6FWogP9j4x80bL.jpg              68.0   \n",
      "32768  2014-01-01   NaN  /zaSf5OG7V8X8gqFvly88zDdRm46.jpg              82.0   \n",
      "\n",
      "      release_date  revenue  runtime production_companies  \\\n",
      "17925            1      NaN      NaN                False   \n",
      "27013           12      NaN      NaN                False   \n",
      "32768           22      NaN      NaN                False   \n",
      "\n",
      "      belongs_to_collection production_countries  \\\n",
      "17925              0.065736                  6.0   \n",
      "27013              1.931659                  7.0   \n",
      "32768              2.185485                  4.3   \n",
      "\n",
      "                                                  genres  overview  \\\n",
      "17925  [{'name': 'Carousel Productions', 'id': 11176}...  Released   \n",
      "27013  [{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...  Released   \n",
      "32768  [{'name': 'Odyssey Media', 'id': 17161}, {'nam...  Released   \n",
      "\n",
      "                  popularity spoken_languages status tagline  vote_average  \\\n",
      "17925                    NaN              NaN    NaN     NaN           NaN   \n",
      "27013                    NaN              NaN    NaN     NaN           NaN   \n",
      "32768  Beware Of Frost Bites              NaN    NaN     NaN           NaN   \n",
      "\n",
      "       vote_count  \n",
      "17925         NaN  \n",
      "27013         NaN  \n",
      "32768         NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25160\\3219681389.py:76: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  movies_df['return'] = pd.Series()\n",
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25160\\3219681389.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_df['return'][i] = x[i]/y[i] if y[i] != 0 else 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>return</th>\n",
       "      <th>original_language</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>12.451801</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>81.0</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>4.043035</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting To Exhale</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>5.090760</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father Of The Bride Part Ii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41760</th>\n",
       "      <td>222848</td>\n",
       "      <td>Caged Heat 3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.661558</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>111109</td>\n",
       "      <td>Century Of Birthing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tl</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41762</th>\n",
       "      <td>67758</td>\n",
       "      <td>Betrayal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-08-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.903007</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>227506</td>\n",
       "      <td>Satan Triumphant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1917</td>\n",
       "      <td>1917-10-21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41764</th>\n",
       "      <td>461257</td>\n",
       "      <td>Queerama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.163015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41765 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                        title      budget      revenue  \\\n",
       "0          862                    Toy Story  30000000.0  373554033.0   \n",
       "1         8844                      Jumanji  65000000.0  262797249.0   \n",
       "2        15602             Grumpier Old Men         0.0          0.0   \n",
       "3        31357            Waiting To Exhale  16000000.0   81452156.0   \n",
       "4        11862  Father Of The Bride Part Ii         0.0   76578911.0   \n",
       "...        ...                          ...         ...          ...   \n",
       "41760   222848              Caged Heat 3000         0.0          0.0   \n",
       "41761   111109          Century Of Birthing         0.0          0.0   \n",
       "41762    67758                     Betrayal         0.0          0.0   \n",
       "41763   227506             Satan Triumphant         0.0          0.0   \n",
       "41764   461257                     Queerama         0.0          0.0   \n",
       "\n",
       "          return original_language  release_year release_date  runtime  \\\n",
       "0      12.451801                en          1995   1995-10-30     81.0   \n",
       "1       4.043035                en          1995   1995-12-15    104.0   \n",
       "2       0.000000                en          1995   1995-12-22    101.0   \n",
       "3       5.090760                en          1995   1995-12-22    127.0   \n",
       "4       0.000000                en          1995   1995-02-10    106.0   \n",
       "...          ...               ...           ...          ...      ...   \n",
       "41760   0.000000                en          1995   1995-01-01     85.0   \n",
       "41761   0.000000                tl          2011   2011-11-17    360.0   \n",
       "41762   0.000000                en          2003   2003-08-01     90.0   \n",
       "41763   0.000000                en          1917   1917-10-21     87.0   \n",
       "41764   0.000000                en          2017   2017-06-09     75.0   \n",
       "\n",
       "       popularity  vote_average  vote_count  \n",
       "0       21.946943           7.7      5415.0  \n",
       "1       17.015539           6.9      2413.0  \n",
       "2       11.712900           6.5        92.0  \n",
       "3        3.859495           6.1        34.0  \n",
       "4        8.387519           5.7       173.0  \n",
       "...           ...           ...         ...  \n",
       "41760    0.661558           3.5         1.0  \n",
       "41761    0.178241           9.0         3.0  \n",
       "41762    0.903007           3.8         6.0  \n",
       "41763    0.003503           0.0         0.0  \n",
       "41764    0.163015           0.0         0.0  \n",
       "\n",
       "[41765 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos el dataset hacia un dataframe en python.\n",
    "movies_df = pd.read_csv('Data/movies_dataset.csv')\n",
    "\n",
    "# Seleccionamos las columnas que necesitamos y eliminamos las que nos piden: video,imdb_id,adult,original_title,poster_path,homepage. Y renombramos algunas.\n",
    "movies_df = movies_df[['id', 'title', 'budget', 'original_language', 'release_date', 'revenue', 'runtime', 'production_companies',  \n",
    "        'belongs_to_collection', 'production_countries', 'genres', 'overview', 'popularity',\n",
    "        'spoken_languages', 'status', 'tagline', 'vote_average', 'vote_count']]\n",
    "movies_df.columns = ['id_peli', 'title', 'budget', 'original_language', 'release_date', 'revenue', 'runtime', 'production_companies',  \n",
    "        'belongs_to_collection', 'production_countries', 'genres', 'overview', 'popularity',\n",
    "        'spoken_languages', 'status', 'tagline', 'vote_average', 'vote_count']\n",
    "\n",
    "# Eliminamos los campos nulos de la columna \"release_date\".\n",
    "movies_df = movies_df.dropna(subset=['release_date']).reset_index(drop=True)\n",
    "\n",
    "# Eliminamos películas duplicadas. Para este caso, tomamos las películas duplicadas con fecha de lanzamiento más reciente.\n",
    "df = movies_df[movies_df.title.isin(list(movies_df[movies_df.title.duplicated()].title))]\n",
    "df['row_count'] = df.sort_values(by=['title','release_date'],ascending=False).groupby(['title']).cumcount()+1\n",
    "index = list(df[df.row_count > 1].id_peli)\n",
    "movies_df = movies_df.set_index('id_peli')\n",
    "movies_df = movies_df.drop(index).reset_index()\n",
    "\n",
    "# Transformando los datos del \"id\" de película a enteros: Me di cuenta mediante este proceso de que existen 3 \"id's\" que son fechas, por lo que eliminé dichas filas.\n",
    "index = []\n",
    "for i in range(len(movies_df)):\n",
    "    try:\n",
    "        movies_df.loc[i,['id_peli']] = int(movies_df.id_peli[i])\n",
    "    except ValueError:\n",
    "        index.append(i)\n",
    "\n",
    "# Visualizamos las filas que no contienen datos relevantes: index = [19714,29472,35543]      \n",
    "print('Filas eliminadas del dataset por no contener información relevante: ',movies_df.loc[index])\n",
    "\n",
    "# Eliminamos las filas.\n",
    "movies_df = movies_df.drop(index)\n",
    "\n",
    "# Seleccionamos las películas con \"status\" = 'Released'.\n",
    "movies_df = movies_df[movies_df.status == 'Released']\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Por último vamos a examinar si existen filas duplicadas en nuestro dataframe.\n",
    "# Utilizamos primeramente el método drop_duplicates().\n",
    "movies_df = movies_df.drop_duplicates()\n",
    "\n",
    "# Después buscamos si existen \"id's\" repetidos después del método.\n",
    "dfx = movies_df.groupby('id_peli')['id_peli'].count() > 1\n",
    "dfx = pd.DataFrame(dfx)\n",
    "index = list(dfx[dfx.id_peli == True].index)\n",
    "\n",
    "# Creamos un DF temporal con el objetivo de obtener las filas con 'id's' duplicados.\n",
    "dfx = pd.DataFrame()\n",
    "for i in index:\n",
    "    dfx = pd.concat([dfx,movies_df[movies_df.id_peli == i]])\n",
    "\n",
    "# Tomamos las filas duplicadas que están en segundo lugar y las eliminamos.\n",
    "index = list(dfx[1::2].index)\n",
    "movies_df = movies_df.drop(index).reset_index(drop=True)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Rellenar valores nulos en los campos \"budget\" y \"revenue\" por 0.\n",
    "movies_df['revenue'] = movies_df.revenue.fillna(0)\n",
    "movies_df['budget'] = movies_df.budget.fillna(0)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# De haber fechas, deberán tener el formato AAAA-mm-dd, además, deberán crear la columna \"release_year\", donde extraerán el año de la fecha de estreno.\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df['release_date'])\n",
    "movies_df['release_year'] = movies_df['release_date'].apply(lambda x: x.year)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget, cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0.\n",
    "movies_df['budget'] = movies_df.budget.astype(float)\n",
    "def returns(x,y):\n",
    "    movies_df['return'] = pd.Series()\n",
    "    for i in range(len(x)):\n",
    "        movies_df['return'][i] = x[i]/y[i] if y[i] != 0 else 0\n",
    "returns(movies_df.revenue,movies_df.budget)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Creamos una función lambda que nos va a ayudar a pasar los strings a listas de diccionarios.\n",
    "a_lista = lambda x: eval(x)\n",
    "\n",
    "# Separamos las columnas con sus respectivos \"id_peli\" en 5 diferentes DF's.\n",
    "df1 = movies_df[['id_peli','production_companies']].reset_index(drop=True)\n",
    "df2 = movies_df[['id_peli','belongs_to_collection']].reset_index(drop=True)\n",
    "df3 = movies_df[['id_peli','production_countries']].reset_index(drop=True)\n",
    "df4 = movies_df[['id_peli','genres']].reset_index(drop=True)\n",
    "df5 = movies_df[['id_peli','spoken_languages']].reset_index(drop=True)\n",
    "\n",
    "# Ahora que ya hemos utilizado las columnas que necesitamos para desanidar las columnas anidadas, podemos eliminarlas de nuestro dataframe de películas, ya que la información está en\n",
    "# nuevos dataframes.\n",
    "movies_df = movies_df[['id_peli', 'title', 'budget', 'revenue', 'return', 'original_language', 'release_year', 'release_date', 'runtime', 'popularity', 'vote_average', 'vote_count']]\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Convertimos los campos anidados de nuestro dataset inicial, de strings a listas de diccionarios. En total son 5 columnas anidadas.\n",
    "df1['production_companies'] = df1['production_companies'].apply(a_lista)\n",
    "\n",
    "df2 = df2.dropna().reset_index(drop=True)\n",
    "df2['belongs_to_collection'] = df2['belongs_to_collection'].apply(a_lista)\n",
    "\n",
    "df3['production_countries'] = df3['production_countries'].apply(a_lista)\n",
    "\n",
    "df4['genres'] = df4['genres'].apply(a_lista)\n",
    "\n",
    "df5 = df5.dropna().reset_index(drop=True)\n",
    "df5['spoken_languages'] = df5['spoken_languages'].apply(a_lista)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "\n",
    "# Dejamos la columna \"release_date\" como datetime. Y capitalizamos las letras de los titulos para homogenizar.\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df.release_date)\n",
    "movies_df['title'] = movies_df.title.apply(lambda x: x.title())\n",
    "movies_df['original_language'] = movies_df.original_language.astype(str)\n",
    "movies_df['original_language'] = movies_df.original_language.apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "if not os.path.exists('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/'):\n",
    "    os.mkdir('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/')\n",
    "movies_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/movies.csv',index=False)\n",
    "\n",
    "# Visualizamos el dataframe.\n",
    "pd.read_csv('clean_data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>production_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41760</th>\n",
       "      <td>222848</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>111109</td>\n",
       "      <td>[{'iso_3166_1': 'PH', 'name': 'Philippines'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41762</th>\n",
       "      <td>67758</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>227506</td>\n",
       "      <td>[{'iso_3166_1': 'RU', 'name': 'Russia'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41764</th>\n",
       "      <td>461257</td>\n",
       "      <td>[{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_peli                               production_countries\n",
       "0         862  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "1        8844  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "2       15602  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "3       31357  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "4       11862  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "...       ...                                                ...\n",
       "41760  222848  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "41761  111109      [{'iso_3166_1': 'PH', 'name': 'Philippines'}]\n",
       "41762   67758  [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "41763  227506           [{'iso_3166_1': 'RU', 'name': 'Russia'}]\n",
       "41764  461257   [{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]\n",
       "\n",
       "[41765 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desanidado de columnas y creación de 5 nuevos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================================================================\n",
    "# Creación del DF \"productoras_df\" y del DF \"id_productoras_df\".\n",
    "# Lo que sigue es obtener el dataframe de las productoras asociadas a cada película.\n",
    "# sourcery skip: use-fstring-for-concatenation\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df1)):\n",
    "    df = pd.DataFrame(df1.production_companies[i])\n",
    "    df['id'] = df1.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "dfx.columns = ['productora','id_peli']\n",
    "\n",
    "# Ahora creamos el dataframe de las productoras únicas con un id único.\n",
    "productoras_df = dfx.productora.unique()\n",
    "productoras_df = pd.DataFrame(productoras_df,columns=['productora'])\n",
    "productoras_df = productoras_df.reset_index()\n",
    "productoras_df.columns = ['id_prod','productora']\n",
    "productoras_df['id_prod'] = productoras_df.id_prod.apply(lambda x: x+1)\n",
    "productoras_df['productora'] = productoras_df.productora.apply(lambda x: x.title())\n",
    "\n",
    "\n",
    "# Por último agregamos los \"id's\" de las productoras al dataframe de las productoras asociadas a películas y eliminamos la columna que contiene el nombre de la productora para reducir el \n",
    "# uso de memoria.\n",
    "dfx = dfx.merge(productoras_df)\n",
    "dfx = dfx.drop('productora',axis=1)\n",
    "id_productoras_df = dfx\n",
    "id_productoras_df['id_peli'] = id_productoras_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "productoras_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/productoras.csv',index=False)\n",
    "id_productoras_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/prod_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"franquicias_df\" y del DF \"id_franquicias_df\"\n",
    "# Obtenemos el dataframe de las franquicias asociadas a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df2)):\n",
    "    df = pd.DataFrame([df2.belongs_to_collection[i]])\n",
    "    df['id'] = df2.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de las franquicias únicas con un id único.\n",
    "dfx = dfx.drop(['poster_path','backdrop_path'],axis=1)\n",
    "dfx.columns = ['id_peli','franquicia']\n",
    "franquicias_df = dfx.franquicia.unique()\n",
    "franquicias_df = pd.DataFrame(franquicias_df,columns=['franquicia']).reset_index()\n",
    "franquicias_df.columns = ['id_franq','franquicia']\n",
    "franquicias_df['id_franq'] = franquicias_df.id_franq.apply(lambda x: x+1)\n",
    "franquicias_df = franquicias_df[['id_franq','franquicia']]\n",
    "franquicias_df['franquicia'] = franquicias_df.franquicia.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de las franquicias al dataframe de las franquicias asociadas a películas y eliminamos la columna que contiene el nombre de la franquicia para reducir el \n",
    "# uso de memoria.\n",
    "id_franquicias_df = dfx.merge(franquicias_df)\n",
    "id_franquicias_df = id_franquicias_df.drop(['franquicia'],axis=1)\n",
    "id_franquicias_df['id_peli'] = id_franquicias_df.id_peli.astype(int) \n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "franquicias_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/franquicias.csv',index=False)\n",
    "id_franquicias_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/franq_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"paises_df\" y del DF \"id_paises_df\"\n",
    "# Obtenemos el dataframe de los países asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df3)):\n",
    "    df = pd.DataFrame(df3.production_countries[i])\n",
    "    df['id'] = df3.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los países únicos con un id único.\n",
    "dfx.columns = ['iso_3166_1','pais','id_peli']\n",
    "dfx['dummy'] = dfx.iso_3166_1 + ' ' + dfx.pais\n",
    "paises_df = dfx.dummy.unique()\n",
    "paises_df = pd.DataFrame(paises_df,columns=['pais']).reset_index()\n",
    "paises_df.columns = ['id_pais','pais']\n",
    "paises_df['abrev'] = paises_df.pais.apply(lambda x: x[:2])\n",
    "paises_df['pais'] = paises_df.pais.apply(lambda x: x[3:])\n",
    "paises_df['id_pais'] = paises_df.id_pais.apply(lambda x: x + 1)\n",
    "paises_df['pais'] = paises_df.pais.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los países al dataframe de los países asociadas a películas y eliminamos la columna que contiene el nombre del país para reducir el \n",
    "# uso de memoria.\n",
    "dfx['pais'] = dfx.pais.apply(lambda x: x.title())\n",
    "id_paises_df = dfx.merge(paises_df)\n",
    "id_paises_df = id_paises_df.drop(['iso_3166_1','pais','dummy','abrev'],axis=1)\n",
    "id_paises_df['id_peli'] = id_paises_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "paises_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/paises.csv',index=False)\n",
    "id_paises_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/pais_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"generos_df\" y del DF \"id_generos_df\"\n",
    "# Obtenemos el dataframe de los generos asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df4)):\n",
    "    df = pd.DataFrame(df4.genres[i])\n",
    "    df['id'] = df4.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los generos únicos con un id único.\n",
    "dfx.columns = ['id_peli','genero']\n",
    "generos_df = pd.DataFrame(dfx.genero.unique(),columns=['genero']).reset_index()\n",
    "generos_df.columns = ['id_gen','genero']\n",
    "generos_df['id_gen'] = generos_df.id_gen.apply(lambda x: x + 1)\n",
    "generos_df['genero'] = generos_df.genero.apply(lambda x: x.title())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los generos al dataframe de los generos asociadas a películas y eliminamos la columna que contiene el nombre del genero para reducir el \n",
    "# uso de memoria.\n",
    "id_generos_df = dfx.merge(generos_df)\n",
    "id_generos_df = id_generos_df.drop(['genero'],axis=1)\n",
    "id_generos_df['id_peli'] = id_generos_df.id_peli.astype(int)\n",
    "id_generos_df.columns = ['id_peli','id_gen']\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "generos_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/generos.csv',index=False)\n",
    "id_generos_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/gen_movies.csv',index=False)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creación del DF \"lenguajes_df\" y del DF \"id_lenguajes_df\"\n",
    "# Obtenemos el dataframe de los lenguajes asociados a cada película.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(df5)):\n",
    "    df = pd.DataFrame(df5.spoken_languages[i])\n",
    "    df['id'] = df5.id_peli[i]\n",
    "    dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Ahora creamos el dataframe de los lenguajes únicos con un id único.\n",
    "dfx.columns = ['iso_639_1','lenguaje','id_peli']\n",
    "dfx['dummy'] = dfx.iso_639_1 + ' ' + dfx.lenguaje\n",
    "lenguajes_df = pd.DataFrame(dfx.dummy.unique(),columns=['lenguaje'])\n",
    "lenguajes_df['abrev'] = lenguajes_df.lenguaje.apply(lambda x: x[:2])\n",
    "lenguajes_df['lenguaje'] = lenguajes_df.lenguaje.apply(lambda x: x[3:])\n",
    "lenguajes_df = lenguajes_df.reset_index()\n",
    "lenguajes_df.columns = ['id_leng','lenguaje','abrev']\n",
    "lenguajes_df['id_leng'] = lenguajes_df.id_leng.apply(lambda x: x + 1)\n",
    "lenguajes_df = lenguajes_df[lenguajes_df.abrev.isin(list(movies_df.original_language.unique()))]\n",
    "lenguajes_df['lenguaje'] = lenguajes_df.lenguaje.apply(lambda x: x.title())\n",
    "lenguajes_df['abrev'] = lenguajes_df.abrev.apply(lambda x: x.lower())\n",
    "\n",
    "# Por último, agregamos los \"id's\" de los lenguajes al dataframe de los lenguajes asociadas a películas y eliminamos la columna que contiene el nombre del lenguaje para reducir el \n",
    "# uso de memoria.\n",
    "id_lenguajes_df = dfx.merge(lenguajes_df)\n",
    "id_lenguajes_df = id_lenguajes_df.drop(['iso_639_1','lenguaje','dummy','abrev'],axis=1)\n",
    "id_lenguajes_df['id_peli'] = id_lenguajes_df.id_peli.astype(int)\n",
    "\n",
    "# Creamos los .csv llamados \"productoras\", \"prod_movies\".\n",
    "lenguajes_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/lenguajes.csv',index=False)\n",
    "id_lenguajes_df.to_csv('C:/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/clean_data/leng_movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_pais</th>\n",
       "      <th>pais</th>\n",
       "      <th>abrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>United States Of America</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>AQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>Gibraltar</td>\n",
       "      <td>GI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>158</td>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159</td>\n",
       "      <td>Honduras</td>\n",
       "      <td>HN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>GN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_pais                      pais abrev\n",
       "0          1  United States Of America    US\n",
       "1          2                   Germany    DE\n",
       "2          3            United Kingdom    GB\n",
       "3          4                    France    FR\n",
       "4          5                     Italy    IT\n",
       "..       ...                       ...   ...\n",
       "155      156                Antarctica    AQ\n",
       "156      157                 Gibraltar    GI\n",
       "157      158         Brunei Darussalam    BN\n",
       "158      159                  Honduras    HN\n",
       "159      160                    Guinea    GN\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paises_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>id_pais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45552</th>\n",
       "      <td>132873</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45553</th>\n",
       "      <td>16403</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45554</th>\n",
       "      <td>277690</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45555</th>\n",
       "      <td>321530</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45556</th>\n",
       "      <td>160372</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45557 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli  id_pais\n",
       "0          862        1\n",
       "1         8844        1\n",
       "2        15602        1\n",
       "3        31357        1\n",
       "4        11862        1\n",
       "...        ...      ...\n",
       "45552   132873      156\n",
       "45553    16403      157\n",
       "45554   277690      158\n",
       "45555   321530      159\n",
       "45556   160372      160\n",
       "\n",
       "[45557 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_paises_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del dataset \"credits.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================================================================\n",
    "# Ingresamos el dataset.\n",
    "credits_df = pd.read_csv('Data/credits.csv')\n",
    "\n",
    "# Dividimos el dataset en dos dataframe's\n",
    "elenco_df = credits_df[['id','cast']]\n",
    "productores_df = credits_df[['id','crew']]\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Eliminamos los nan, reestablecemos el índice y convertimos las strings en listas de diccionarios de ambos datasets.\n",
    "productores_df = productores_df.dropna().reset_index(drop=True)\n",
    "productores_df['crew'] = productores_df['crew'].apply(a_lista)\n",
    "elenco_df = elenco_df.dropna().reset_index(drop=True)\n",
    "elenco_df['cast'] = elenco_df['cast'].apply(a_lista)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Desanidamos la columna \"crew\".\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(productores_df)):\n",
    "    df = pd.DataFrame(productores_df.crew[i])\n",
    "    if not df.empty:\n",
    "        df = df[['id', 'job', 'name']][df.job == 'Director']\n",
    "        df = df.drop('job',axis=1)\n",
    "        df['id'] = productores_df.id[i]\n",
    "        dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "\n",
    "# Obtenemos solo los directores del dataset \"credits.csv\" y la tabla que asocia películas con directores.\n",
    "id_directores_df = dfx\n",
    "id_directores_df.columns = ['id_peli', 'director']\n",
    "directores_df = id_directores_df.director.unique()\n",
    "directores_df = pd.DataFrame(directores_df).reset_index()\n",
    "directores_df.columns = ['id_dir','director']\n",
    "directores_df['id_dir'] = directores_df.id_dir.apply(lambda x: x + 1)\n",
    "directores_df['director'] = directores_df.director.apply(lambda x: x.title())\n",
    "id_directores_df = id_directores_df.merge(directores_df).drop('director',axis=1)\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Desanidamos la columna \"cast\" y creamos el dataframe de personajes.\n",
    "dfx = pd.DataFrame()\n",
    "for i in range(len(elenco_df)):\n",
    "    df = pd.DataFrame(elenco_df.cast[i])\n",
    "    if not df.empty:\n",
    "        df = df[['id', 'name']]\n",
    "        df['id'] = elenco_df.id[i]\n",
    "        dfx = pd.concat([dfx,df])\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "dfx.columns = ['id_peli', 'actor']\n",
    "id_personajes_actores_df = dfx\n",
    "\n",
    "# También creamos el dataset de actores con el mismo objetivo.\n",
    "dfx = id_personajes_actores_df.actor.unique()\n",
    "dfx = pd.DataFrame(dfx).reset_index()\n",
    "dfx.columns = ['id_act','actor']\n",
    "dfx['id_act'] = dfx.id_act.apply(lambda x: x + 1)\n",
    "dfx['actor'] = dfx.actor.apply(lambda x: x.title())\n",
    "actores_df = dfx\n",
    "\n",
    "# Ahora eliminamos la columna de actores y de personajes para solo dejar \"id's\"\n",
    "id_personajes_actores_df = id_personajes_actores_df.merge(actores_df)\n",
    "id_personajes_actores_df = id_personajes_actores_df.drop(['actor'],axis=1)\n",
    "id_personajes_actores_df\n",
    "\n",
    "# ====================================================================================================================================\n",
    "# Creamos los archivos .csv de los dataframe's resultantes.\n",
    "directores_df.to_csv('clean_data/directores.csv',index=False)\n",
    "id_directores_df.to_csv('clean_data/dir_movies.csv',index=False)\n",
    "actores_df.to_csv('clean_data/actores.csv',index=False)\n",
    "id_personajes_actores_df.to_csv('clean_data/pers_movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección de desarrollo del dataset para el modelo de recomendación\n",
    "\n",
    "Esta parte de la limpieza se desarrolló a la par del desarrollo del EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_24196\\196826973.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfx = pd.read_csv('Data/movies_dataset.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>title</th>\n",
       "      <th>original_language</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>en</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>en</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>en</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting To Exhale</td>\n",
       "      <td>en</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father Of The Bride Part Ii</td>\n",
       "      <td>en</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41760</th>\n",
       "      <td>222848</td>\n",
       "      <td>Caged Heat 3000</td>\n",
       "      <td>en</td>\n",
       "      <td>0.661558</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>111109</td>\n",
       "      <td>Century Of Birthing</td>\n",
       "      <td>tl</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41762</th>\n",
       "      <td>67758</td>\n",
       "      <td>Betrayal</td>\n",
       "      <td>en</td>\n",
       "      <td>0.903007</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>227506</td>\n",
       "      <td>Satan Triumphant</td>\n",
       "      <td>en</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41764</th>\n",
       "      <td>461257</td>\n",
       "      <td>Queerama</td>\n",
       "      <td>en</td>\n",
       "      <td>0.163015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41765 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                        title original_language  popularity  \\\n",
       "0          862                    Toy Story                en   21.946943   \n",
       "1         8844                      Jumanji                en   17.015539   \n",
       "2        15602             Grumpier Old Men                en   11.712900   \n",
       "3        31357            Waiting To Exhale                en    3.859495   \n",
       "4        11862  Father Of The Bride Part Ii                en    8.387519   \n",
       "...        ...                          ...               ...         ...   \n",
       "41760   222848              Caged Heat 3000                en    0.661558   \n",
       "41761   111109          Century Of Birthing                tl    0.178241   \n",
       "41762    67758                     Betrayal                en    0.903007   \n",
       "41763   227506             Satan Triumphant                en    0.003503   \n",
       "41764   461257                     Queerama                en    0.163015   \n",
       "\n",
       "       vote_average  vote_count  release_year  \n",
       "0               7.7      5415.0          1995  \n",
       "1               6.9      2413.0          1995  \n",
       "2               6.5        92.0          1995  \n",
       "3               6.1        34.0          1995  \n",
       "4               5.7       173.0          1995  \n",
       "...             ...         ...           ...  \n",
       "41760           3.5         1.0          1995  \n",
       "41761           9.0         3.0          2011  \n",
       "41762           3.8         6.0          2003  \n",
       "41763           0.0         0.0          1917  \n",
       "41764           0.0         0.0          2017  \n",
       "\n",
       "[41765 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# franquicia, genero, productora, paises, lenguaje, overview, release_year\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "dfx = pd.read_csv('Data/movies_dataset.csv')\n",
    "df = df[['id_peli', 'title', 'original_language', 'popularity', 'vote_average', 'vote_count', 'release_year']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45461</th>\n",
       "      <td>439050</td>\n",
       "      <td>Rising and falling between a man and woman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45462</th>\n",
       "      <td>111109</td>\n",
       "      <td>An artist struggles to finish his work while a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45463</th>\n",
       "      <td>67758</td>\n",
       "      <td>When one of her hits goes wrong, a professiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45464</th>\n",
       "      <td>227506</td>\n",
       "      <td>In a small town live two brothers, one a minis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45465</th>\n",
       "      <td>461257</td>\n",
       "      <td>50 years after decriminalisation of homosexual...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45463 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_peli                                           overview\n",
       "0         862  Led by Woody, Andy's toys live happily in his ...\n",
       "1        8844  When siblings Judy and Peter discover an encha...\n",
       "2       15602  A family wedding reignites the ancient feud be...\n",
       "3       31357  Cheated on, mistreated and stepped on, the wom...\n",
       "4       11862  Just when George Banks has recovered from his ...\n",
       "...       ...                                                ...\n",
       "45461  439050        Rising and falling between a man and woman.\n",
       "45462  111109  An artist struggles to finish his work while a...\n",
       "45463   67758  When one of her hits goes wrong, a professiona...\n",
       "45464  227506  In a small town live two brothers, one a minis...\n",
       "45465  461257  50 years after decriminalisation of homosexual...\n",
       "\n",
       "[45463 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = dfx[['id','overview']]\n",
    "index = []\n",
    "for i in range(len(dfx)):\n",
    "    try:\n",
    "        dfx.loc[i,['id']] = int(dfx.id[i])\n",
    "    except ValueError:\n",
    "        index.append(i)\n",
    "dfx.columns = ['id_peli','overview']\n",
    "dfx = dfx.drop(index)\n",
    "dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza que surgió durante el desarrollo del modelo.\n",
    "\n",
    "Parte del código que vamos a utilizar para generar esta parte de la limpieza la podemos obtener del EDA. Aunque también en esta parte comienza una parte del preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\1153106459.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lista = list(df[['id_peli','title','vote_count', 'vote_average','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[df.vote_count >= 15].id_peli)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>title</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>return</th>\n",
       "      <th>original_language</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>franquicia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>12.451801</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>81.0</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>Toy Story Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>4.043035</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Grumpy Old Men Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting To Exhale</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>5.090760</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father Of The Bride Part Ii</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13131</th>\n",
       "      <td>432789</td>\n",
       "      <td>The Incredible Jessica James</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.667067</td>\n",
       "      <td>6.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13132</th>\n",
       "      <td>434873</td>\n",
       "      <td>It Stains The Sands Red</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-10-08</td>\n",
       "      <td>92.0</td>\n",
       "      <td>8.471866</td>\n",
       "      <td>5.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13133</th>\n",
       "      <td>18098</td>\n",
       "      <td>Arabian Nights</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-04-30</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2.266456</td>\n",
       "      <td>6.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13134</th>\n",
       "      <td>455661</td>\n",
       "      <td>In A Heartbeat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.821780</td>\n",
       "      <td>8.3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13135</th>\n",
       "      <td>14008</td>\n",
       "      <td>Cadet Kelly</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002-03-07</td>\n",
       "      <td>101.0</td>\n",
       "      <td>4.392389</td>\n",
       "      <td>5.2</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13136 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                         title      budget      revenue  \\\n",
       "0          862                     Toy Story  30000000.0  373554033.0   \n",
       "1         8844                       Jumanji  65000000.0  262797249.0   \n",
       "2        15602              Grumpier Old Men         0.0          0.0   \n",
       "3        31357             Waiting To Exhale  16000000.0   81452156.0   \n",
       "4        11862   Father Of The Bride Part Ii         0.0   76578911.0   \n",
       "...        ...                           ...         ...          ...   \n",
       "13131   432789  The Incredible Jessica James         0.0          0.0   \n",
       "13132   434873       It Stains The Sands Red         0.0          0.0   \n",
       "13133    18098                Arabian Nights         0.0          0.0   \n",
       "13134   455661                In A Heartbeat         0.0          0.0   \n",
       "13135    14008                   Cadet Kelly         0.0          0.0   \n",
       "\n",
       "          return original_language  release_year release_date  runtime  \\\n",
       "0      12.451801                en          1995   1995-10-30     81.0   \n",
       "1       4.043035                en          1995   1995-12-15    104.0   \n",
       "2       0.000000                en          1995   1995-12-22    101.0   \n",
       "3       5.090760                en          1995   1995-12-22    127.0   \n",
       "4       0.000000                en          1995   1995-02-10    106.0   \n",
       "...          ...               ...           ...          ...      ...   \n",
       "13131   0.000000                en          2017   2017-01-27     83.0   \n",
       "13132   0.000000                en          2016   2016-10-08     92.0   \n",
       "13133   0.000000                en          2000   2000-04-30    175.0   \n",
       "13134   0.000000                en          2017   2017-06-01      4.0   \n",
       "13135   0.000000                en          2002   2002-03-07    101.0   \n",
       "\n",
       "       popularity  vote_average  vote_count                 franquicia  \n",
       "0       21.946943           7.7      5415.0       Toy Story Collection  \n",
       "1       17.015539           6.9      2413.0                        NaN  \n",
       "2       11.712900           6.5        92.0  Grumpy Old Men Collection  \n",
       "3        3.859495           6.1        34.0                        NaN  \n",
       "4        8.387519           5.7       173.0                        NaN  \n",
       "...           ...           ...         ...                        ...  \n",
       "13131    5.667067           6.2        37.0                        NaN  \n",
       "13132    8.471866           5.6        21.0                        NaN  \n",
       "13133    2.266456           6.9        21.0                        NaN  \n",
       "13134   20.821780           8.3       146.0                        NaN  \n",
       "13135    4.392389           5.2       145.0                        NaN  \n",
       "\n",
       "[13136 rows x 13 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franq = pd.read_csv('clean_data/franquicias.csv')\n",
    "id_franq = pd.read_csv('clean_data/franq_movies.csv')\n",
    "franq = id_franq.merge(franq).drop('id_franq',axis=1)\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "df = df.merge(franq,how='left')\n",
    "lista = list(df[['title','vote_count','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[:len(df) - 36000].index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['title','vote_count','popularity','release_year']][df.release_year < 1990].sort_values(by=['release_year']).index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['id_peli','title','vote_count', 'vote_average','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[df.vote_count >= 15].id_peli)\n",
    "df = df[df.id_peli.apply(lambda x: x in lista)].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['title', 'vote_count', 'popularity', 'release_year'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tinma\\OneDrive\\Escritorio\\HENRY\\PI1_MLOps_HENRY\\Data_Cleansing.ipynb Celda 15\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tinma/OneDrive/Escritorio/HENRY/PI1_MLOps_HENRY/Data_Cleansing.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mvote_count\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mpopularity\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mrelease_year\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelease_year\u001b[39m\u001b[39m'\u001b[39m)[:\u001b[39m50\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tinma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3808\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3809\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3810\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3812\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tinma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6111\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6113\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6115\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tinma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6171\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6169\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6170\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 6171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6173\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   6174\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['title', 'vote_count', 'popularity', 'release_year'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df[['title','vote_count','popularity','release_year']].sort_values(by='release_year')[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Más variaciones a la limpieza y preprocesamiento\n",
    "\n",
    "Ahora vamos a utilizar el acercamiento en donde utilizamos el género, la productora, la franquicia, el titulo y el original_language. Nos dimos cuenta que actores, productoras y directores nos daban recomendaciones poco acertadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>The Double Life Of Veronique</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.661817</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29122</th>\n",
       "      <td>Lee Rock</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.807175</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29183</th>\n",
       "      <td>Robotrix</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.667275</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29265</th>\n",
       "      <td>Ultrà</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.266692</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29382</th>\n",
       "      <td>The Crucifer Of Blood</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.512575</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40957</th>\n",
       "      <td>Dragonheart: Battle For The Heartfire</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.794894</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40956</th>\n",
       "      <td>Drone</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8.413334</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40099</th>\n",
       "      <td>Asylum Of Darkness</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.474061</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40995</th>\n",
       "      <td>What Happened To Monday</td>\n",
       "      <td>598.0</td>\n",
       "      <td>60.581223</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39595</th>\n",
       "      <td>The Bar</td>\n",
       "      <td>122.0</td>\n",
       "      <td>20.720113</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24436 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  vote_count  popularity  \\\n",
       "1011            The Double Life Of Veronique       154.0    9.661817   \n",
       "29122                               Lee Rock         3.0    1.807175   \n",
       "29183                               Robotrix         3.0    0.667275   \n",
       "29265                                  Ultrà        10.0    0.266692   \n",
       "29382                  The Crucifer Of Blood         5.0    0.512575   \n",
       "...                                      ...         ...         ...   \n",
       "40957  Dragonheart: Battle For The Heartfire        25.0    7.794894   \n",
       "40956                                  Drone        55.0    8.413334   \n",
       "40099                     Asylum Of Darkness         4.0    0.474061   \n",
       "40995                What Happened To Monday       598.0   60.581223   \n",
       "39595                                The Bar       122.0   20.720113   \n",
       "\n",
       "       release_year  \n",
       "1011           1991  \n",
       "29122          1991  \n",
       "29183          1991  \n",
       "29265          1991  \n",
       "29382          1991  \n",
       "...             ...  \n",
       "40957          2017  \n",
       "40956          2017  \n",
       "40099          2017  \n",
       "40995          2017  \n",
       "39595          2017  \n",
       "\n",
       "[24436 rows x 4 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franq = pd.read_csv('clean_data/franquicias.csv')\n",
    "id_franq = pd.read_csv('clean_data/franq_movies.csv')\n",
    "franq = id_franq.merge(franq).drop('id_franq',axis=1)\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "df = df.merge(franq,how='left')\n",
    "lista = list(df[['title','vote_count','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[:len(df) - 36000].index)\n",
    "df = df.drop(lista)\n",
    "df = df[['title','vote_count','popularity','release_year']][df.release_year > 1990].sort_values(by=['release_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\3349443906.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lista = list(df[['id_peli','title','vote_count', 'vote_average','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[df.vote_count >= 15].id_peli)\n"
     ]
    }
   ],
   "source": [
    "franq = pd.read_csv('clean_data/franquicias.csv')\n",
    "id_franq = pd.read_csv('clean_data/franq_movies.csv')\n",
    "franq = id_franq.merge(franq).drop('id_franq',axis=1)\n",
    "df = pd.read_csv('clean_data/movies.csv')\n",
    "df = df.merge(franq,how='left')\n",
    "lista = list(df[['title','vote_count','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[:len(df) - 36000].index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['title','vote_count','popularity','release_year']][df.release_year < 1975].sort_values(by=['release_year']).index)\n",
    "df = df.drop(lista)\n",
    "lista = list(df[['id_peli','title','vote_count', 'vote_average','popularity','release_year']].sort_values(by=['vote_count','popularity','release_year'])[df.vote_count >= 15].id_peli)\n",
    "df = df[df.id_peli.apply(lambda x: x in lista)].reset_index(drop=True)\n",
    "df = df[['id_peli',\t'title', 'franquicia']]\n",
    "\n",
    "genero = pd.read_csv('clean_data/generos.csv')\n",
    "id_genero = pd.read_csv('clean_data/gen_movies.csv')\n",
    "productora = pd.read_csv('clean_data/productoras.csv')\n",
    "id_productora = pd.read_csv('clean_data/prod_movies.csv')\n",
    "actor = pd.read_csv('clean_data/actores.csv')\n",
    "id_actor = pd.read_csv('clean_data/pers_movies.csv')\n",
    "director = pd.read_csv('clean_data/directores.csv')\n",
    "id_director = pd.read_csv('clean_data/dir_movies.csv')\n",
    "\n",
    "genero = id_genero.merge(genero).drop('id_gen',axis=1)\n",
    "productora = id_productora.merge(productora).drop('id_prod',axis=1)\n",
    "actor = id_actor.merge(actor).drop('id_act',axis=1)\n",
    "director = id_director.merge(director).drop('id_dir',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>title</th>\n",
       "      <th>franquicia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Toy Story Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Grumpy Old Men Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting To Exhale</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father Of The Bride Part Ii</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>432789</td>\n",
       "      <td>The Incredible Jessica James</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>434873</td>\n",
       "      <td>It Stains The Sands Red</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>18098</td>\n",
       "      <td>Arabian Nights</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>455661</td>\n",
       "      <td>In A Heartbeat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15075</th>\n",
       "      <td>14008</td>\n",
       "      <td>Cadet Kelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15076 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                         title                 franquicia\n",
       "0          862                     Toy Story       Toy Story Collection\n",
       "1         8844                       Jumanji                        NaN\n",
       "2        15602              Grumpier Old Men  Grumpy Old Men Collection\n",
       "3        31357             Waiting To Exhale                        NaN\n",
       "4        11862   Father Of The Bride Part Ii                        NaN\n",
       "...        ...                           ...                        ...\n",
       "15071   432789  The Incredible Jessica James                        NaN\n",
       "15072   434873       It Stains The Sands Red                        NaN\n",
       "15073    18098                Arabian Nights                        NaN\n",
       "15074   455661                In A Heartbeat                        NaN\n",
       "15075    14008                   Cadet Kelly                        NaN\n",
       "\n",
       "[15076 rows x 3 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_list = []\n",
    "for x in actor.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        actor[actor.id_peli == x].loc[i].actor.replace(' ', '')\n",
    "        for i in actor[actor.id_peli == x].index\n",
    "    )\n",
    "    act_list.append(lista_1)\n",
    "    \n",
    "dir_list = []\n",
    "for x in director.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        director[director.id_peli == x].loc[i].director.replace(' ', '')\n",
    "        for i in director[director.id_peli == x].index\n",
    "    )\n",
    "    dir_list.append(lista_1)\n",
    "    \n",
    "gen_list = []\n",
    "for x in genero.id_peli.unique():\n",
    "    lista_1 = [x]\n",
    "    lista_1.extend(\n",
    "        genero[genero.id_peli == x].loc[i].genero.strip()\n",
    "        for i in genero[genero .id_peli == x].index\n",
    "    )\n",
    "    gen_list.append(lista_1)\n",
    "    \n",
    "    \n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'dir_{i}' for i in range(41))\n",
    "dir_df = pd.DataFrame(dir_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'gen_{i}' for i in range(8))\n",
    "gen_df = pd.DataFrame(gen_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "lista = ['id_peli']\n",
    "lista.extend(f'act_{i}' for i in range(306))\n",
    "act_df = pd.DataFrame(act_list,columns=lista).set_index('id_peli')\n",
    "\n",
    "# # act_df = act_df.iloc[:,:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_0</th>\n",
       "      <th>act_1</th>\n",
       "      <th>act_2</th>\n",
       "      <th>act_3</th>\n",
       "      <th>act_4</th>\n",
       "      <th>act_5</th>\n",
       "      <th>act_6</th>\n",
       "      <th>act_7</th>\n",
       "      <th>act_8</th>\n",
       "      <th>act_9</th>\n",
       "      <th>...</th>\n",
       "      <th>act_40</th>\n",
       "      <th>act_41</th>\n",
       "      <th>act_42</th>\n",
       "      <th>act_43</th>\n",
       "      <th>act_44</th>\n",
       "      <th>act_45</th>\n",
       "      <th>act_46</th>\n",
       "      <th>act_47</th>\n",
       "      <th>act_48</th>\n",
       "      <th>act_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_peli</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>TomHanks</td>\n",
       "      <td>TimAllen</td>\n",
       "      <td>DonRickles</td>\n",
       "      <td>JimVarney</td>\n",
       "      <td>WallaceShawn</td>\n",
       "      <td>JohnRatzenberger</td>\n",
       "      <td>AnniePotts</td>\n",
       "      <td>JohnMorris</td>\n",
       "      <td>LaurieMetcalf</td>\n",
       "      <td>R.LeeErmey</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>TomHanks</td>\n",
       "      <td>XanderBerkeley</td>\n",
       "      <td>GabrielJarret</td>\n",
       "      <td>KevinBacon</td>\n",
       "      <td>EdHarris</td>\n",
       "      <td>EndreHules</td>\n",
       "      <td>BillPaxton</td>\n",
       "      <td>GarySinise</td>\n",
       "      <td>KathleenQuinlan</td>\n",
       "      <td>MaryKateSchellhardt</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TomHanks</td>\n",
       "      <td>MykeltiWilliamson</td>\n",
       "      <td>AaronMichaelLacey</td>\n",
       "      <td>StephenBridgewater</td>\n",
       "      <td>SallyField</td>\n",
       "      <td>RobinWright</td>\n",
       "      <td>GarySinise</td>\n",
       "      <td>JoeAlaskey</td>\n",
       "      <td>MaryEllenTrainor</td>\n",
       "      <td>SiobhanFallon</td>\n",
       "      <td>...</td>\n",
       "      <td>JohnWilliamGalt</td>\n",
       "      <td>IsabelRose</td>\n",
       "      <td>RichardD'Alessandro</td>\n",
       "      <td>GeoffreyBlake</td>\n",
       "      <td>VanessaRoth</td>\n",
       "      <td>DickCavett</td>\n",
       "      <td>TiffanySalerno</td>\n",
       "      <td>TiffanySalerno</td>\n",
       "      <td>LazarusJackson</td>\n",
       "      <td>LazarusJackson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9800</th>\n",
       "      <td>TomHanks</td>\n",
       "      <td>AnnaDeavereSmith</td>\n",
       "      <td>MarySteenburgen</td>\n",
       "      <td>AntonioBanderas</td>\n",
       "      <td>JoeyPerillo</td>\n",
       "      <td>CharlesTechman</td>\n",
       "      <td>LisaTalerico</td>\n",
       "      <td>TomDetrik</td>\n",
       "      <td>RobertaMaxwell</td>\n",
       "      <td>GeneBorkan</td>\n",
       "      <td>...</td>\n",
       "      <td>BuzzKilman</td>\n",
       "      <td>MarkSorensenJr.</td>\n",
       "      <td>JeffreyWilliamson</td>\n",
       "      <td>StephanieRothHaberle</td>\n",
       "      <td>BillRowe</td>\n",
       "      <td>FordWheeler</td>\n",
       "      <td>JuliusErving</td>\n",
       "      <td>GaryGoetzman</td>\n",
       "      <td>KennethUtt</td>\n",
       "      <td>JimRoche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>TomHanks</td>\n",
       "      <td>DanaIvey</td>\n",
       "      <td>RossMalinger</td>\n",
       "      <td>DavidHydePierce</td>\n",
       "      <td>RosieO'Donnell</td>\n",
       "      <td>GabyHoffmann</td>\n",
       "      <td>RitaWilson</td>\n",
       "      <td>MegRyan</td>\n",
       "      <td>BillPullman</td>\n",
       "      <td>FrancesConroy</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264269</th>\n",
       "      <td>MariyaFomina</td>\n",
       "      <td>DmitriYendaltsev</td>\n",
       "      <td>BorisPolunin</td>\n",
       "      <td>ViktoriyaRaykova</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370213</th>\n",
       "      <td>SonitaAlidazeh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75608</th>\n",
       "      <td>RobertGardner</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282308</th>\n",
       "      <td>CharlesPrince</td>\n",
       "      <td>GabrielleLange</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258907</th>\n",
       "      <td>BarbaraHammer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42889 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  act_0              act_1              act_2  \\\n",
       "id_peli                                                         \n",
       "862            TomHanks           TimAllen         DonRickles   \n",
       "568            TomHanks     XanderBerkeley      GabrielJarret   \n",
       "13             TomHanks  MykeltiWilliamson  AaronMichaelLacey   \n",
       "9800           TomHanks   AnnaDeavereSmith    MarySteenburgen   \n",
       "858            TomHanks           DanaIvey       RossMalinger   \n",
       "...                 ...                ...                ...   \n",
       "264269     MariyaFomina   DmitriYendaltsev       BorisPolunin   \n",
       "370213   SonitaAlidazeh               None               None   \n",
       "75608     RobertGardner               None               None   \n",
       "282308    CharlesPrince     GabrielleLange               None   \n",
       "258907    BarbaraHammer               None               None   \n",
       "\n",
       "                      act_3           act_4             act_5         act_6  \\\n",
       "id_peli                                                                       \n",
       "862               JimVarney    WallaceShawn  JohnRatzenberger    AnniePotts   \n",
       "568              KevinBacon        EdHarris        EndreHules    BillPaxton   \n",
       "13       StephenBridgewater      SallyField       RobinWright    GarySinise   \n",
       "9800        AntonioBanderas     JoeyPerillo    CharlesTechman  LisaTalerico   \n",
       "858         DavidHydePierce  RosieO'Donnell      GabyHoffmann    RitaWilson   \n",
       "...                     ...             ...               ...           ...   \n",
       "264269     ViktoriyaRaykova            None              None          None   \n",
       "370213                 None            None              None          None   \n",
       "75608                  None            None              None          None   \n",
       "282308                 None            None              None          None   \n",
       "258907                 None            None              None          None   \n",
       "\n",
       "              act_7             act_8                act_9  ...  \\\n",
       "id_peli                                                     ...   \n",
       "862      JohnMorris     LaurieMetcalf           R.LeeErmey  ...   \n",
       "568      GarySinise   KathleenQuinlan  MaryKateSchellhardt  ...   \n",
       "13       JoeAlaskey  MaryEllenTrainor        SiobhanFallon  ...   \n",
       "9800      TomDetrik    RobertaMaxwell           GeneBorkan  ...   \n",
       "858         MegRyan       BillPullman        FrancesConroy  ...   \n",
       "...             ...               ...                  ...  ...   \n",
       "264269         None              None                 None  ...   \n",
       "370213         None              None                 None  ...   \n",
       "75608          None              None                 None  ...   \n",
       "282308         None              None                 None  ...   \n",
       "258907         None              None                 None  ...   \n",
       "\n",
       "                  act_40           act_41               act_42  \\\n",
       "id_peli                                                          \n",
       "862                 None             None                 None   \n",
       "568                 None             None                 None   \n",
       "13       JohnWilliamGalt       IsabelRose  RichardD'Alessandro   \n",
       "9800          BuzzKilman  MarkSorensenJr.    JeffreyWilliamson   \n",
       "858                 None             None                 None   \n",
       "...                  ...              ...                  ...   \n",
       "264269              None             None                 None   \n",
       "370213              None             None                 None   \n",
       "75608               None             None                 None   \n",
       "282308              None             None                 None   \n",
       "258907              None             None                 None   \n",
       "\n",
       "                       act_43       act_44       act_45          act_46  \\\n",
       "id_peli                                                                   \n",
       "862                      None         None         None            None   \n",
       "568                      None         None         None            None   \n",
       "13              GeoffreyBlake  VanessaRoth   DickCavett  TiffanySalerno   \n",
       "9800     StephanieRothHaberle     BillRowe  FordWheeler    JuliusErving   \n",
       "858                      None         None         None            None   \n",
       "...                       ...          ...          ...             ...   \n",
       "264269                   None         None         None            None   \n",
       "370213                   None         None         None            None   \n",
       "75608                    None         None         None            None   \n",
       "282308                   None         None         None            None   \n",
       "258907                   None         None         None            None   \n",
       "\n",
       "                 act_47          act_48          act_49  \n",
       "id_peli                                                  \n",
       "862                None            None            None  \n",
       "568                None            None            None  \n",
       "13       TiffanySalerno  LazarusJackson  LazarusJackson  \n",
       "9800       GaryGoetzman      KennethUtt        JimRoche  \n",
       "858                None            None            None  \n",
       "...                 ...             ...             ...  \n",
       "264269             None            None            None  \n",
       "370213             None            None            None  \n",
       "75608              None            None            None  \n",
       "282308             None            None            None  \n",
       "258907             None            None            None  \n",
       "\n",
       "[42889 rows x 50 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tinma\\AppData\\Local\\Temp\\ipykernel_25852\\927220160.py:18: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  act_df['elenco'] = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "# prod_df['productoras'] = pd.Series()\n",
    "# for i in range(len(prod_df.columns)):\n",
    "#     prod_df.iloc[:,i] = prod_df.iloc[:,i].astype(str)\n",
    "# for x in prod_df.index:\n",
    "#     lista_x = list(prod_df.loc[x,:].unique())\n",
    "#     try:\n",
    "#         lista_x.remove('nan')\n",
    "#         lista_x.remove('None')\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "#     prod_df.loc[x,'productoras'] = ' '.join(lista_x)\n",
    "# for i in prod_df.columns:\n",
    "#     if i != 'productoras':\n",
    "#         prod_df.drop(i,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "act_df['elenco'] = pd.Series()\n",
    "for i in range(len(act_df.columns)):\n",
    "    act_df.iloc[:,i] = act_df.iloc[:,i].astype(str)\n",
    "for x in act_df.index:\n",
    "    lista_x = list(act_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    act_df.loc[x,'elenco'] = ' '.join(lista_x)\n",
    "for i in act_df.columns:\n",
    "    if i != 'elenco':\n",
    "        act_df.drop(i,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "dir_df['cineastas'] = pd.Series()\n",
    "for i in range(len(dir_df.columns)):\n",
    "    dir_df.iloc[:,i] = dir_df.iloc[:,i].astype(str)\n",
    "for x in dir_df.index:\n",
    "    lista_x = list(dir_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    dir_df.loc[x,'cineastas'] = ' '.join(lista_x)\n",
    "for i in dir_df.columns:\n",
    "    if i != 'cineastas':\n",
    "        dir_df.drop(i,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "gen_df['genero'] = pd.Series()\n",
    "for i in range(len(gen_df.columns)):\n",
    "    gen_df.iloc[:,i] = gen_df.iloc[:,i].astype(str)\n",
    "for x in gen_df.index:\n",
    "    lista_x = list(gen_df.loc[x,:].unique())\n",
    "    try:\n",
    "        lista_x.remove('nan')\n",
    "        lista_x.remove('None')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    gen_df.loc[x,'genero'] = ' '.join(lista_x)\n",
    "for i in gen_df.columns:\n",
    "    if i != 'genero':\n",
    "        gen_df.drop(i,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elenco</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_peli</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>TomHanks TimAllen DonRickles JimVarney Wallace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>TomHanks XanderBerkeley GabrielJarret KevinBac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TomHanks MykeltiWilliamson AaronMichaelLacey S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9800</th>\n",
       "      <td>TomHanks AnnaDeavereSmith MarySteenburgen Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>TomHanks DanaIvey RossMalinger DavidHydePierce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264269</th>\n",
       "      <td>MariyaFomina DmitriYendaltsev BorisPolunin Vik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370213</th>\n",
       "      <td>SonitaAlidazeh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75608</th>\n",
       "      <td>RobertGardner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282308</th>\n",
       "      <td>CharlesPrince GabrielleLange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258907</th>\n",
       "      <td>BarbaraHammer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42889 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    elenco\n",
       "id_peli                                                   \n",
       "862      TomHanks TimAllen DonRickles JimVarney Wallace...\n",
       "568      TomHanks XanderBerkeley GabrielJarret KevinBac...\n",
       "13       TomHanks MykeltiWilliamson AaronMichaelLacey S...\n",
       "9800     TomHanks AnnaDeavereSmith MarySteenburgen Anto...\n",
       "858      TomHanks DanaIvey RossMalinger DavidHydePierce...\n",
       "...                                                    ...\n",
       "264269   MariyaFomina DmitriYendaltsev BorisPolunin Vik...\n",
       "370213                                      SonitaAlidazeh\n",
       "75608                                        RobertGardner\n",
       "282308                        CharlesPrince GabrielleLange\n",
       "258907                                       BarbaraHammer\n",
       "\n",
       "[42889 rows x 1 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_peli', 'title', 'franquicia', 'genero', 'cineastas', 'elenco'], dtype='object')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_peli</th>\n",
       "      <th>title</th>\n",
       "      <th>word_bag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Toy Story ToyStoryCollection Animation Comedy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Jumanji  Family Adventure Fantasy JoeJohnston ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Grumpier Old Men GrumpyOldMenCollection Comedy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting To Exhale</td>\n",
       "      <td>Waiting To Exhale  Comedy Romance Drama Forest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father Of The Bride Part Ii</td>\n",
       "      <td>Father Of The Bride Part Ii  Comedy CharlesShy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>432789</td>\n",
       "      <td>The Incredible Jessica James</td>\n",
       "      <td>The Incredible Jessica James  Comedy Romance J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>434873</td>\n",
       "      <td>It Stains The Sands Red</td>\n",
       "      <td>It Stains The Sands Red  Comedy Drama Horror C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>18098</td>\n",
       "      <td>Arabian Nights</td>\n",
       "      <td>Arabian Nights  Family Fantasy Drama SteveBarr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>455661</td>\n",
       "      <td>In A Heartbeat</td>\n",
       "      <td>In A Heartbeat  Animation Comedy Family Romanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15075</th>\n",
       "      <td>14008</td>\n",
       "      <td>Cadet Kelly</td>\n",
       "      <td>Cadet Kelly  Comedy LarryShaw LarryShaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15076 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_peli                         title  \\\n",
       "0          862                     Toy Story   \n",
       "1         8844                       Jumanji   \n",
       "2        15602              Grumpier Old Men   \n",
       "3        31357             Waiting To Exhale   \n",
       "4        11862   Father Of The Bride Part Ii   \n",
       "...        ...                           ...   \n",
       "15071   432789  The Incredible Jessica James   \n",
       "15072   434873       It Stains The Sands Red   \n",
       "15073    18098                Arabian Nights   \n",
       "15074   455661                In A Heartbeat   \n",
       "15075    14008                   Cadet Kelly   \n",
       "\n",
       "                                                word_bag  \n",
       "0      Toy Story ToyStoryCollection Animation Comedy ...  \n",
       "1      Jumanji  Family Adventure Fantasy JoeJohnston ...  \n",
       "2      Grumpier Old Men GrumpyOldMenCollection Comedy...  \n",
       "3      Waiting To Exhale  Comedy Romance Drama Forest...  \n",
       "4      Father Of The Bride Part Ii  Comedy CharlesShy...  \n",
       "...                                                  ...  \n",
       "15071  The Incredible Jessica James  Comedy Romance J...  \n",
       "15072  It Stains The Sands Red  Comedy Drama Horror C...  \n",
       "15073  Arabian Nights  Family Fantasy Drama SteveBarr...  \n",
       "15074  In A Heartbeat  Animation Comedy Family Romanc...  \n",
       "15075            Cadet Kelly  Comedy LarryShaw LarryShaw  \n",
       "\n",
       "[15076 rows x 3 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(gen_df.reset_index(),how='left').merge(dir_df.reset_index(),how='left').merge(act_df.reset_index(),how='left')\n",
    "x = df.columns\n",
    "df['word_bag'] = df[df.columns[1]].astype(str) + ' ' + df[df.columns[2]].astype(str).apply(lambda x: x.replace(' ','')) + ' ' + df[df.columns[3]].astype(str) + ' ' + df[df.columns[4]].astype(str) + ' ' + df[df.columns[4]].astype(str)\n",
    "df['word_bag'] = df.word_bag.astype(str)\n",
    "df['word_bag'] = df.word_bag.apply(lambda x: x.replace('nan',''))\n",
    "for i in df.columns:\n",
    "    if i not in ['word_bag','id_peli','title']:\n",
    "        df.drop(i,axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_data/movies_model.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
